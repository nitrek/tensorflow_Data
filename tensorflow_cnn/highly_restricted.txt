hello customer this email contains highly restricted information regarding security system and lock combinations the lock combination for server room is the lock combination for server room is the lock combination for server room is the lock combination for server room is
hello admin this email contains highly confidential information regarding financial summaries which are to be kept undisclosed till november keep this information safe at all times
hello customer this email contains highly confidential information regarding the passwords of your different bank accounts here are your passwords please do not share these passwords with anyone thank you
disney pixar mickey and nemo pinocchio and buzz lightyear cinderella and lightning mcqueen the merger of the legendary walt disney and everything we create kids adore pixar was a match made in cartoon heaven disney had released all of pixar s movies before but with their contract about to run out after the release of cars the merger made perfect sense with the merger in the two companies could collaborate freely and easily did the merger work well take a look at the successful movies that disney pixar has given birth to since wall e up brave and inside out the merger didn t just enable the two to collaborate but also helped to breath new air into disney s other divisions first tangled and more recently frozen have garnered huge attention at the box office and beyond with frozen becoming the fifth highest grossing movie ever sirius xm radio in july of satellite radio officially had one provider when sirius satellite radio joined forces with rival xm satellite radio the merger was officially announced more than a year prior but the actual merger was delayed due to one tiny problem when satellite radio first began in the fcc granted only two licenses under one condition that either of the holders would not acquire control of the other oops so sirius and xm filed the proper paperwork with the fcc allowed the fcc to investigate the merger and waited patiently for the approval they needed today percent of new cars come with siriusxm pre installed and a free month trial and net income and revenue continue to increase exxon mobil big oil got even bigger in when exxon and mobil signed an billion agreement to merge and form exxonmobil not only did it become the largest company in the world it reunited its century former selves john d rockefeller s standard oil company of new jersey exxon and standard oil company of new york mobil the merger was so big in fact that the ftc required a massive restructuring of many of exxon mobil s gas stations in order to avoid outright monopolization despite the ftc s unanimous approval of the merger exxonmobil remains the strongest leader in the oil market with a huge hold on the international market and dramatic earnings so was the merger a success absolutely some even predict that after shell s recent acquisition of bg group that exxonmobil is about to make yet another big move in oil by merging again only time will tell new york central pennsylvania railroad corporate mergers don t always work out and in the history of mergers and acquisitions penn central sticks out as one of the poorest in a time when transportation trends were shifting towards super highways and air travel the pennsylvania railroad company and the new york central railroad company decided to merge and form penn central the merger was officially approved in only for it to file for bankruptcy just two years later with billion in assets at the onset it seemed shocking this could happen but strict regulations inflating labor costs and executive clashing all came together like a corporate bermuda triangle thousands were affected by the bankruptcy and it s safe to say this was one merger that utterly flopped daimler benz chrysler in mercedes benz manufacturer daimler benz merged with u s auto maker chrysler to create daimler chrysler for billion the logic was obvious to create a trans atlantic car making powerhouse that would dominate the markets but by daimler benz sold chrysler to the cerberus capital management firm which specializes in restructuring troubled companies for a mere billion so what happened it may be another case of corporate culture clash chrysler was nowhere near the league of high end daimler benz and many felt that daimler strutted in and tried to control the folks on the chrysler such clashes tend to undermine a new alliance combine that with dragging sales and a recession and you have a recipe for corporate divorce and another example of a less than stellar corporate merger yahoo facebook almost sometimes bad mergers or acquisitions can be avoided with one company choosing to stick it out on their own in yahoo saw the blossoming facebook as a youngster with a promising future yahoo made an offer to acquire the company for billion but facebook gave a hard no ceo mark zuckerberg was just about to launch facebook s newsfeed and anticipated the company would be worth much more than yahoo s offer he couldn t have been more right today facebook is worth around billion earning billion in alone the ugly sears kmart towards the end of the century department store legend sears found itself struggling to stay afloat amidst the successes of big box stores like target and walmart and high end department stores like saks fifth avenue hedge fund investor eddie lampert whose hedge fund controlled kmart decided to acquire sears and merge the two companies the merged companies became sears holdings in and seemed to be a promising endeavor at the time however the two merged companies continued their downward spiral with some blaming sears identity crisis as a carrier of clothes home goods and appliances with no strong niche or brand others say their strategic investments for the future were lacking rendering their strategy unsustainable whatever the causes it s clear the acquisition has been a failure so far and the future doesn t look promising sears holdings is speculated as the next big retail failure having lost billion over the past four years aol time warner at the height of the internet craze two media companies merged together to form what was seen as a revolutionary move to fuse the old with the new in old school media giant time warner consolidated with american online aol the internet and email provider of the people for a whopping billion it was considered a combination of the best of both worlds but boy was that false though on paper the merge occurred the cultures of these two dynamically different companies never did the dot com bubble burst and the decline of dial up internet access spelled disaster for the future in aol time warner reported a billion dollar write down which lead to a billion dollar yearly loss finally in the two companies finally split in a sort of corporate divorce quaker snapple in grocery store legend quaker oats acquired the new kid on the block snapple for billion fresh from their success with gatorade quaker oats wanted to make snapple drinks their next success story despite criticisms from wall street that they paid billion too much for the fruity drink company quaker oats dove head first into a new marketing campaign and set out to bring snapple to every grocery store and chain restaurant they could however their efforts failed miserably snapple had found its niche in small independent stores and gas stations backed by a quirky and fun advertising strategy quaker didn t seem to grasp the snapple identity and after just months sold snapple for million for those of you doing the math that s a loss of million for each day that the company owned snapple ouch
hello admin this email contains highly restricted information on private symmetric cryptographic keys following are the cryptographic keys
hello admin this email contains highly confidential information regarding biometrics for customer id the biometrics data is stored on server and has the following login credentials username password keep these credentials safe at all times
the afcee low risk site closure manual lorsc manual is a comprehensive decision support tool to help site managers determine if they have a low risk site by combining key concepts information and experience into one dynamic decision support tool this information can then be used to assist site managers build effective exit strategies for closing low risk sites and or reducing long term monitoring intensity an exit strategy for a given site can be strengthened by using multiple lines of evidence therefore this guide provides weight of evidence decision logic to build consensus between site stakeholders developed by gsi environmental inc in conjunction with the air force center for engineering and the environment afcee the lorsc manual provides site stakeholders with a specific focused technology transfer roadmap that can be used to support regulatory decision making by outlining how low risk sites work why they won t cause a future environmental problem why they should be closed or at a minimum should be monitored only on a very limited basis the manual is intended to provide a methodology that can be used by site personnel to identify the type of usaf site or any other site and its probability for potential closure and evaluate and prioritize sites based on threat criteria grouping sites as lorsc type a b or c lorsc type a sites strongest case for low risk closure or reduced monitoring lorsc type b sites moderately good case for low risk closure or reduced monitoring lorsc type c sites more difficult for low risk closure or reduced monitoring ladies and gentlemen this letter agreement sets forth our agreement and understanding as to the essential terms of the sale to the purchaser by the seller of the seller s business the business located in and engaged in the parties intend this letter agreement to be binding and enforceable and that it will inure to the benefit of the parties and their respective successors and assigns purchased assets at the closing the purchaser will purchase substantially all of the assets associated with the business including all inventories all intellectual property all accounts and notes receivable all contracts and agreements all equipment all legally assignable government permits and certain documents files and records containing technical support and other information pertaining to the operation of the business assumed liabilities the purchaser will assume as of the closing date only those liabilities and obligations i arising in connection with the operation of the business by the purchaser after the closing date and ii arising after the closing date in connection with the performance by the purchaser of the contracts and agreements associated with the business purchase price the purchase price will be payable in cash in immediately available funds on the closing date pre closing covenants the parties will use their reasonable best efforts to obtain all necessary third party and government consents including all certificates permits and approvals required in connection with the purchaser s operation of thebusiness the seller will continue to operate the business consistent with past practice the parties agree to prepare negotiate and execute a purchase agreement which will reflect the terms set forth in this letter agreement and will contain customary representations and warranties conditions to obligation the purchaser and the seller will be obligated to consummate the acquisition of the business unless the purchaser has failed to obtain despite the parties reasonable best efforts all certificates permits and approvals that are required in connection with purchaser s operation of the business due diligence the seller agrees to cooperate with the purchaser s due diligence investigation of the business and to provide the purchaser and its representatives with prompt and reasonable access to key employees and to books records contracts and other information pertaining to the business the due diligence information confidentiality non competition the purchaser will use the due diligence information solely for the purpose of the purchaser s due diligence investigation of the business and unless and until the parties consummate the acquisition of the business the purchaser its affiliates directors officers employees advisors and agents the purchaser s representatives will keep the due diligence information strictly confidential the purchaser will disclose the due diligence information only to those representatives of the purchaser who need to know such information for the purpose of consummating the acquisition of the business the purchaser agrees to be responsible for any breach of this paragraph by any of the purchaser s representatives in the event the acquisition of the business is not consummated the purchaser will return to the seller any materials containing due diligence information or will certify in writing that all such materials or copies of such materials have been destroyed the purchaser also will not use any due diligence information to compete with the seller in the event that the acquisition of the business is not consummated the provisions of this paragraph will survive the termination of this letter agreement employees of the business until the consummation of the acquisition of the business or in the event that the parties do not consummate the acquisition of the business the purchaser will not solicit or recruit the employees of the business exclusive dealing until the seller will not enter into any agreement discussion or negotiation with or provide information to or solicit encourage entertain or consider any inquiries or proposals from any other corporation fire or other person with respect to a the possible disposition of a material portion of the business or b any business combination involving the business whether by way of merger consolidation share exchange or other transaction if for any reason the acquisition of the business is not consummated and the seller is unable to enforce the provisions of this letter agreement the buyer will pay to the seller a break up fee which will equal the sum of of the purchase price and the seller s expenses in connection with the negotiation of the acquisition public announcement all press releases and public announcements relating to the acquisition of the business will be agreed to and prepared jointly by the seller and the purchaser expenses subject to the provisions in paragraph of this letter agreement each party will pay all of its expenses including legal fees incurred in connection with the acquisition of the business indemnification the seller represents and warrants that the purchaser will not incur any liability in connection with the consummation of the acquisition of the business to any third party with whom the seller or its agents have had discussions regarding the disposition of the business and the seller agrees to indemnify defend and hold harmless the purchaser its officers directors stockholders lenders and affiliates from any claims by or liabilities to such third parties including any legal or other expenses incurred in connection with the defense of such claims the covenants contained in this paragraph will survive the termination of this letter agreement if you are in agreement with the terms of this letter agreement please sign in the space provided below and return a signed copy to by the close of business on upon receipt of a signed copy of this letter we will proceed with our plans for consummating the transaction in a timely manner
any foreign or domestic regional economic financial social or political conditions including changes therein in general ii changes in any financial debt credit capital or banking markets or conditions including any disruption thereof iii changes in interest currency or exchange rates or the price of any commodity security or market index iv changes or proposed changes in legal or regulatory conditions including changes in law gaap or other accounting principles or requirements or standards interpretations or enforcement thereof v changes in the company s and its subsidiaries industries in general vi seasonal fluctuations in the business of the company and its subsidiaries consistent with the past experience of the company and its subsidiaries vii any change in the market price or trading volume of any securities of the company or any of its subsidiaries or the change in or failure of the company to meet or the publication of any report regarding any internal or public projections forecasts budgets or estimates of or relating to the company or any of its subsidiaries for any period including with respect to revenue earnings cash flow or cash position it being understood that the underlying causes of such decline or failure may if they are not otherwise excluded from the definition of company material effect be taken into account in determining whether a company material adverse effect has occurred viii the occurrence escalation outbreak or worsening of any hostilities war police action acts of terrorism or military conflicts whether or not pursuant to the declaration of an emergency or war ix the existence occurrence or continuation of any force majeure events including any earthquakes floods hurricanes tropical storms fires or other natural disasters or any national international or regional calamity x any legal action arising from or relating to this agreement or the transactions contemplated by this agreement except as it relates to any breach or violation of this agreement by the company xi the execution announcement performance or existence of this agreement the identity of parent the taking or not taking of any action to the extent required by this agreement or the pendency or contemplated consummation of the transactions including any actual or potential loss or impairment after the date hereof of any contract or any customer supplier partner employee or other business relation due to any of the foregoing in this subclause xi xii compliance by the company and its subsidiaries with the terms of this agreement including the failure to take any action explicitly restricted by this agreement xiii any actions taken or not taken with the express prior written consent of parent xiv any matters disclosed in section of the company disclosure letter or xv any actions taken by parent its affiliates or any of their respective representatives after the date hereof provided further that the exceptions set forth in subclauses i ii iii iv v and viii immediately above shall not apply and such circumstances shall be taken into account in determining whether a company material adverse effect has occurred or would reasonably be expected to occur to the extent that such event condition change occurrence or development of a state of circumstances has a disproportionate effect on the company and its subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses and in the case of subclause ix immediately above has a disproportionate effect on company and its company subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses in the geographic regions in which the company and the its subsidiaries operate and provided further that with respect to references to company material adverse effect in the representations and warranties set forth in section and section the exception set forth in subclauses x and xi shall not apply
an acquisition or merger is not a frequent event for my organization however it seems like in the past year or so we have worked on a number of these activities so it seems like it may be time to create a formalized checklist for the it department items that need to be addressed during an acquisition to get the ball rolling i am listing some items that i consider to be important to the infrastructure security folks like me i know this list is not exhaustive or complete it is a work in progress and will need to be refined for each event since they are all different some of these may be done in the due diligence but the rubber hits the road during the implementation so without further ado absorbing a new acquisition to do list general incomplete private wan connectivity days or more lead time depending on location flexible ip addressing scheme to absorb devices on new network s internet firewall changes ports source addresses nat etc dns ownership and management changing registrars changing dns nameservers use a dig tool to get information concerning current configuration menandmice network hygiene how clean are the devices and what personnel habits need to be changed device inventory what effort will it take to do this software licensing inventory what about handling loss of staff knowledge documentation of processes procedures configurations phone list sharing e mail addressbook sharing e mail system integration anti spam anti virus calendar sharing erp process integration resource access permissions financial reporting integration accounts payable receivable tax etc staff reporting structure other hr activities benefits payroll etc i welcome your insight and experience on the many other activities you feel is important to address during a merger acquisition
confidentialour ref november chief executiveall authorized institutionsdear sir madam operational incidents watchthe hong kong monetary authority published today the enclosed fourth issue of operational incidents watch the operational incidents watch is a periodic newsletter to share with the industry the major lessons learnt from selected significant operational incidents that have happened in the banking sector it aims at facilitating authorized institutions ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this connection we expect ais senior management to ensure that their relevant business lines and operational risk management functions will take into account the operational incidents watch to review and enhance where appropriate the relevant risk management controls including any applicable customer education efforts if there are any questions on the operational incidents watch please contact mr parry tang at or ms debora chan at yours faithfully henry chengexecutive director banking supervision enclhong kong monetary authority page no november incidents watch is a periodic newsletter published by the banking supervision department of the hong kong monetary authority hkma it summarises the major lessons learnt from selected operational that have happened in the banking industry and led to impact on relevant customers or material financial losses of the authorized institutions ais concerned it aims at facilitating ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this newsletter the modus operandi or the factors and key control loopholes leading to two operational incidents are summarised i use of fraudulent documents and information for obtaining factoring financing and ii unauthorised access to an ai s premises by a staff member during her garden leave period an ai suffered from a material fraud loss in the provision of factoring financing to borrowers due to inadequate controls and verification for detecting the fraudulent documents and information provided by the borrowers modus operandi factors leading to the incidentthe ai granted trade finance facilities including factoring and export financing to a couple of borrowers when the borrowers started utilising the factoring limits the ai initially conducted detailed reviews of the related transaction documents e g the sales invoices and shipping documents submitted by the borrowers and sent debt confirmations to the approved debtors to verify the genuineness of the underlying transactions however after several transactions the ai no due to sensitivity considerations the incidents mentioned in this newsletter could be prepared on the basis of synthesis of multiple incidents or certain details of the relevant operational incidents might have been omitted operational incidents watchuse of fraudulent documents and information for obtaining factoring financingoperational incidents watch issue no november hong kong monetary authority page adequate reviews of the transaction documents submitted by the borrowers besides the ai did not perform sufficient checking of the company information of new debtors added to the approved list and the borrowers requests for changing the contact information of certain approved debtors for instance the e mail addresses even with private e mail domain or the identities of the contact persons of a new debtor provided by the borrowers were not duly verified through independent sources by exploiting these loopholes the borrowers were able to obtain factoring financing from the ai by providing fictitious contact information of the approved debtors and producing bogus sales invoices and shipping documents in the subsequent transactions control loopholes and lessons learnti there was a lack of well established on going verification of the transaction documents provided by the borrowers the ai set an inappropriate level of threshold for checking the bills of lading and it mainly relied on debt confirmations sent to the borrowers approved debtors via the contact details provided by the borrowers to ascertain the genuineness of the underlying transactions between the borrowers and their debtors subsequent investigation of the case unveiled that there were substantial mismatches between the information stated on the bills of lading submitted by the borrowers and the records maintained by those independent service providers of shipping information e g the international maritime bureau and sea searcher those mismatches had not been detected earlier because the sizes of those underlying trade transactions were all individually below the checking threshold at the relevant time while the ai did not have a checking threshold that referred to the aggregate utilization of the factoring limits ii the contact information of the approved debtors e g e mail and business addresses phone numbers etc provided by the borrowers were not adequately verified by the ai s relevant staff members through reliable independent sources in addition the responsibility of verifying the company information of approved debtors provided by borrowers had not been clearly defined among the relationship management team the factoring credit team and the factoring operations team of the ai as a result official company searches and contactoperational incidents watch issue no november hong kong monetary authority page for some approved debtors were either omitted or not promptly verified even when the monthly statements of some approved debtors were returned due to invalid addresses the factoring operations team did not promptly ask the factoring credit team to verify the debtors addresses thereby resulting in delay in detection of the suspicious activities iii the fraud loss could have been reduced if a probation period had been imposed on those newly approved debtors with limited verifiable particulars so that the related factoring financing would not be made available to the borrowers until the ai had received payments from those new debtors the incident involved a staff member of an ai entering the ai s premises and printing out confidential information during her garden leave period without prior consent modus operandi factors leading to the incidentthe staff member who was given an official notice of redundancy by the ai was placed on garden leave prior to her termination of employment however the staff member was not required to surrender her building access card and no formal notification was given to her regarding the restrictions that among others she could not enter the ai s premises without prior consent during the leave period given that the staff member was instructed by her manager to complete certain handover tasks prior to the start of the garden leave she returned to the ai during the leave period having noted that her access to the ai s office area was denied she requested the ai s office administration team to reactivate her access on the ground that she needed to complete the handover work the office administration team then granted her a one day temporary access to the ai s office area without consulting the human resources or the manager of the staff member further the staff member continued to gain access to the ai s office area after office hours on the next few days by only showing her deactivated building access card andunauthorised access to an ai s premises by a staff member during her garden leave periodoperational incidents watch issue no november hong kong monetary authority page to the building security guards that the access card was not functioning the ai subsequently picked up these irregularities and then conducted a review of the staff member s activities whilst the review found that the staff member printed some confidential documents from the ai s system and took them away from the ai s premises she explained that the information was only used for completing the handover work she then returned the hardcopies of the documents to the ai and signed an undertaking that she had not made copies or disseminated the information to third parties control loopholes and lessons learnti there were inadequate process and controls over staff who were placed on leave pending termination of employment where i formal instruction had not been given to the staff member as well as the manager on their responsibilities and obligations during the garden leave period leading to a misunderstanding by the staff member that she was still allowed to access the ai s premises and it systems in order to complete the handover work and ii the manager failed to complete the ai s procedures for handling exiting employees to collect the building access card from the staff member and remove her it system access rights prior to the commencement of the garden leave ii the office administration team had not adhered to the ai s physical access authorisation procedures appropriate parties of the ai had not been duly consulted before the temporary access to the ai s premises was granted to the staff member iii the building security guards had failed to verify the identities of the staff member and prohibit her access to the ai s premises
dear admin this email contains highly confidential information regarding otp seed values for the areas of asia pacific below are the seed values please keep this information safe
hello customer your card verification value code or cvv code is please keep your cvv number safe and do not share it with anybody thank you
hello customer this email contains highly confidential information regarding your personal identification number or pin please keep your pin safe at all times do not share your pin with anybody else your personal identification number is
part i backgroundtraditionally trading is done by manual operation which requires a trader to open or close position by hand or at least calling a broker to do so benjamin graham once mentioned that many great investors with outstanding investment records always repeat that investor s largest enemy is himself warren buffett also said that a successful investor is one that has the right temperament and the right psychology as we all know manual trading is not only vulnerable to traders psychological and emotional fluctuation but also very inefficient in terms of trading speed and convenience due to the advance of computing technology now almost all financial assets can be electronically traded automated trading system takes advantage of computers to develop and test strategies and to trade financial assets automatically it can help novice traders to avoid emotional trading and also help experienced traders to make trading more efficient and systematic it has been widely used in financial industry and become indispensable for many investors on the other hand automatic trading makes market more liquid and reduces trading cost accordingly in recent years online trading platform also becomes a hot spot of financial engineering innovation many financial technology companies such as quantopian quantconnect motif investing have raised considerable funds from wall street hedge funds like worldquant also provide online simulation and trading environment for individual traders some of these platforms are beautifully designed and very user friendly but when you backtest your strategies they are actually running on the servers hence totally transparent to the company to avoid the risk of exposing the strategies it is safer to do research in local machine and trade through reliable brokers or dma in addition in the online platforms data are transferred in internet with http protocol which may be ok for low frequency trading but not efficient or feasible for high frequency trading sentosa is named after the most popular island resort in singapore the languages i used to write sentosa includes c python r go and javascript the project is hosted at www com where you can download source code and follow all the updates there are three subprojects in sentosa sentosa trading systemsentosa trading system is a multithread message driven highly scalable high frequency automatic trading system the latency can be as low as milliseconds dependent on the distance between you and trading venue servers currently the trading venue is ib so an ib account is required with modular design it can be extended easily to support other trading venues the algorithm module can be written with any language supporting either nanomsg or websocket protocol i have implemented language binding for python r for an illustration purpose it is very easy to add other language support like java matlab haskell go c etc the market data module subscribes to trade and quote taq data so in some literature or book sentosa trading system should be categorized as technical automatic trading system as a contrast with fundamental automatic trading system where the system mainly uses fundamentals as trading signal i don t think this categorization makes much sense because signal is just a result of algorithm module and anything can be a signal technical indicator fundamental ratio macroeconomic index social media news google trends etc sentosa research platformsentosa research platform is essentially an interactive computing environment based on jupyter i will demonstrate how to use r and python to do volatility research in the platform later sentosa web applicationin addition i also developed a web platform for sentosa with django and tornado by which you can monitor sentosa and send orders using web interface i used sentosa to do research and trading for myself although it can be used for real trading here i disclaim all the responsibilities of any loss of any trade through sentosa but if it had helped you make money i don t mind to be treated a cup of coffee sentosa is an ongoing project and more features will be added in the future i will also discuss the future direction of each subproject part ii sentosa trading design overviewwhen designing sentosa trading system my emphasis is on its configurability modularity and scalability in folder sentosa there is a yaml format configuration file named sentosa yml which you can use to customize the system the only requirement is you need to set your own ib account in the global section for paper or real trading sentosa trading system is mainly composed of five modules market data module oms module algorithm module record module and simulation module these modules are purposely decoupled and communications are all through messaging system the trading system also has four running modes record trade simulation and merlion which represent different combination of the five modules figure is the program workflow graph of sentosa trading system workflow of sentosa trading running modesentosa can be running at four modes which is define as follows record modedo not trade just to record all the market information into a simulation file for future usage trade modelaunch all sentosa modules and trade simulation mode or backtesting modereplay historical scenario this is to backtest your algorithm in a simulation environment merlion modemerlion mode is the same as trade mode except that it does not generate simulation file you cannot replay you current trading session as you have no simulation file generated the running mode can be configured in global section in sentosa yml multithreads and messaging systemsentosa is a multithread application implemented with c threads all the threads are created in heap and the pointers are stored in a vector initially i developed sentosa in windows platform and used zmq as internal messaging protocol but when i was trying to port it to linux zmq did not work well with threads in linux zmq created more than ten threads automatically and it messed up with ib s threads somehow i filed zmq bug report and so far it has yet been solved nanomsg is created as a better alternative to zmq by the same author it is simpler to use and has no such issue in multithread environment i replaced all zmq code with nanomsg and chose nanomsg as my internal messaging protocol moduleswith nanomsg as the internal messaging protocol i decouple the system into five basic modules market data module order management system module algorithm module record module and simulation module these modules coexist in one process but in different threads they communicate with messaging system and can be turned off and on according to the four running modes described above modular design makes the system scalable and easier for future development the first three modules represent the three most basic components of an automatic trading system in the following sections i will describe these three modules one by one market data introduction of market datamarket data module is one of the most important components of a trading system generally market data include tick level information about prices and size of bid ask completed trades different data vendors sometimes provide extra information like tag exchange name there are two levels of market data according to the information it provides level market datalevel market data provide the most basic information which includes bid ask price and size and the last traded price and size from the order book point of view these information are from the top of the book so level market data also known as top of book data level market datalevel market data also called order book or market depth provide extra information of partial or whole order book the order book has two long queues of bid and ask orders respectively the queues cancel each other at the top and grow when new limit order comes in the length of the queue is called the depth of order book the order book changes very fast for liquid stocks so the information can be overwhelmingly huge most individual traders use level market data level market data are crucial for day traders especially low latency high frequency traders there are many academic researches on level market data in recent years ib has its own way to deliver market data loosely speaking ib provides both level and level market data reqmktdata is to request level market data reqmktdepth is to request level market data in addition to the raw data ib also provides real time bar data via function reqrealtimebars the real time bar data like the historical bar data also provide open high close low ohcl prices volume weighted average price vwap and trade count information please be noted that ib doesn t provide true tick level data the market data are actually consolidated every milliseconds or so and sent back to client upon request as we are not doing ultra low latency trading and not considering the tick level dynamics a combination of level data and seconds real time bar data should be enough threadsin sentosa trading system market data module involves the following threads connects to ib to request two kinds of data ib s tick level real time market data by reqmktdata ib s seconds real time trade bar data by reqrealtimebars upon data sent back from ib data are sent to thread to update scoreboard a global data structure implemented as a singleton in scoreboard h cpp level market data by calling ib api reqmkdepth tws currently limits users to a maximum of distinct market depth requests this same restriction applies to api clients however api clients may make multiple market depth requests for the same security due to this limitation many algorithms involving order book dynamics cannot be used thread is to update scoreboard upon the market data message when sentosa trading system is running at simulation mode the market data can be from a simulation file aka replay file algorithm modulesentosa trading system provides a framework for traders to write their strategies this framework is called algorithm module this module communicates with oms module through messaging system not many traders are programming experts but in order to implement their strategies they know how to use programming languages to write trading algorithms the most frequently used languages by traders include r matlab python and vba excel sentosa trading system is a message driven system and designed with multiple languages support in mind as long as one language supports nanomsg or websocket it can be used to write trading algorithm currently senotsa supports algorithm module written in three languages including c python and r these three languages represent three ways how algorithm module works in sentosa c traders using c mostly have strong programming skills and higher requirement with trading system s performance and speed in sentosa trading system algorithm module is built into a static library and then used to generate the final executable binary all algorithms in sentosa trading system inherit from an abstract base class algoengine factory pattern is used to create algorithm objects algoengine algofac const string if boost iequals return if boost iequals return return nullptr in sentosa configuration file sentosa yml there is a strategy section to specify you strategy name and trading universe take the following as an example strategies sina athm sohu yy wb renn cyou qunr spy fxi it means there is a strategy called and the trading universe includes stocks etfs sina athm fxi i name the strategy for an illustration purpose so that you can see this is a strategy using technical analysis in real trading traders normally give their strategies totally irrelevant names technical analysis ta indicators are extremely popular with individual traders they normally use it in low frequency trading there are many rules of thumb for ta indicators which are only applicable in low frequency trading environment for high frequency trading you may need to do some adjustment take rsi relative strength index an extremely popular indicator developed by j welles wilder jr as an example rsi is defined as rsi rs where rs averagegain averageloss according to wilder rsi is considered overbought when above and oversold when below if using seconds bar data for stocks trading not so frequently rsi can become very high or low because there are many periods without price change there are two solutions the first one is to use more time periods so that average gain or average loss is not equal to another solution is to set rsi equal to if the price changes are too few in other words the momentum is not obvious when there is no price change information so we just give it a value of the following is a c implementation of the second idea if number of price changes is less than just set rsi to double getrsi double p sz vector double vd p p sz auto i std unique vd begin vd end m distance vd begin i if m return int ob n endindex double result endindex sz endindex p sz ob n result return result some ta indicators working well in low frequency trading do not work at all in high frequency trading one reason is the market data like taq is not enough in high frequency especially for assets with low liquidity another reason is that market noise is significant sometimes dominant in high frequency trading too much unpredicted factors will make the real price trend unclear in this case more research and backtesting are needed to find out what the real value of the trading asset is and after how long the noise will disappear there is a ta library called ta lib written in c and also available in other languages like python go sentosa includes a development version of ta lib version you can also download ta lib version from http ta lib org which is more stable but with less ta indicators pythontraders using python do not have very high requirement on the execution speed and system performance i developed a python package called pysentosa which uses nanomsg protocol to connect to market data module and websocket protocol to connect to oms a demo code is like the following from pysentosa import merlion from ticktype import m merlion target spy m target bita bounds target while true symbol ticktype value m if symbol target if ticktype and value bounds symbol oid m buy symbol while true m oid print ordstatus if filled bounds symbol break sleep elif ticktype and value bounds symbol oid m sell symbol bounds symbol code demonstrates a simple algorithm set a price range with lower bound equal to and upper bound equal to if spy s ask price is lower than try to buy shares if the buy order get filled decrease the lower bound by and wait to buy shares until the ask price hit below but if the bid price is greater than the upper bound value send a sell order of shares spy if get filled increase the upper bound by and wait to sell until the bid price hit beyond the new upper bound value this algorithm can be used to split big order for institutional traders not only is pysentosa a message interface of sentosa it includes a sentosa trading system runtime i use boost python to wrap sentosa trading system into a dynamic library and it will be run as a daemon when you create a merlion object in another words pysentosa is a complete full featured trading system rin contrast with pysentosa i also developed rsentosa with r language which is to demonstrate another way to use sentosa rsentosa is for traders using r language who normally have strong statistics background rsentosa use nanomsg protocol to communicate with both oms and market data module the demo code is as follows library rsentosa c spy bita while v symbol v tktype v value v cat symbol tktype value n if symbol spy if tktype as double value oid buy symbol while oid cat order status n if filled cancelled break sys sleep if filled the algorithm is almost the same as the python version except it does not sell spy no matter what bid price is order management systemoms order management systems is a software system to facilitate and manage the order execution typically through the fix protocol in sentosa oms module gets orders from algorithm module and send them to ib ib gets order from sentosa oms and executes it using its smart routing technology ib api supports two basic type of orders limit order and market order limit orderlimit order has a price limit which guarantees the execution price cannot be worse than it for every stock exchange maintains a limit order book including all the bid ask prices volumes and timestamp information please be noted the trade price can be favorable than limit order price for example if you send a limit order of selling google stock for dollar per share system will fill it with the bid price at the top of the book which will be higher than dollar market ordera market order itself has no price information when a market order is sent out to an exchange the order matching engine will find the currently available best price to execute it market order will normally be filled immediately by matching another limit order at the top of order book you cannot match two market orders because there is no price information in market orders oms design and messaging protocoloms accepts two type of protocols nanomsg and websocket thread will monitor and handle any incoming nanomsg message at port specified as in sentosa yml thread will monitor and handle any incoming websocket message at port specified as sentosa yml oms handles two different protocols but with the same logic i use c function overloading to handle the difference the interface definition is at cpp and implementation is at cpp for nanomsg and cpp for websocket respectively sentosa is a multithread application where there are four threads in oms module sentosa for performance consideration system will preallocate a static array of orders with length of for each instrument in another words one instrument can send at most orders with different order id order replacement is not counted in as the order id is the same this number should be enough for individual traders sentosa oms uses nanomsg as the communication protocol and receives nanomsg text as the instruction sentosa oms opened a socket at the following endpoint string endpoint tcp localhost cr you can customize the port by changing at sentosa yml the protocol specification is also customizable through sentosa yml take the default sentosa yml configuration as an example protocol closeall e closeone f cancelall g lmtorder l mktorder m orderid i where closeallto close all your current position with market order when a nanomsg text starting with e is received closeoneto close one instrument s position as soon as possible the nanomsg format is f symbol for instance f ibm means to close your current ibm holding position with a market order cancelallto cancel all your current outstanding orders of one instrument the nanomsg format is g symobl lmtorderto send a limit order the format is l symbol quantity price allowedmove oid where quantity is a signed integer positive sign means buy and negative means sell price is the limit price allowedmove is the price range in which the order is still considered valid in sentosa oms if the market price moves too far from the limit price the order will be cancelled by oms the logic can be expressed with the following pseudo code if abs marketprice targetlimitprice allowedmove oid else oid oid is the order idmktorderto send a market order the format is m symbol quantity oid orderidto check the status of an order by order id the message format is i oid for instance i means a request to oms to return the status of the order with id equal to oms will send one of the following order s status to client with the format of i oid orderstatus in case the order doesn t exist at all oms will send back if oms send i back it means the order with id equal to has a status of submitted order status are defined like the following enum orderstatus newborn presubmitted submitted inactive filled cancelled you can refer to ib document for the details of order status https www interactivebrokers com en software api apiguide c orderstatus future directionsentosa trading system can be extended in several ways from multithread to multiprocessfrom single machine to clusterfrom ib to other trading venues or direct market access dma if possiblemore languages supportmore modules support risk management module portfolio management part iii sentosa research introductionsearch research platform is a web based interactive computing platform based on jupyter with python and r support you can set it up in your local machine and do research with your data the following is a screenshot sentosa research platformin the following sections i will discuss financial data selection collection and management then i will showcase two research tasks using r and python respectively the first is garch family volatility comparative study with low frequency data and the second is true volatility calculation with high frequency data data selection collection and managementin the first place successful trading starts with good quality data with good quality data particularly quantitative data trader can do meaningful research for equity trading some commonly used data types include trade data quote data fundamental data macroeconomic data risk factor data news data social media data and option data daily ohlc trade data and some macroeconomic data are normally available for free others are mostly not free some of which are expensive because of the information edge traders can get from them for the paid data services you need to choose to pay for processed data or raw data or both processed data eg pe pb ratio are more convenient and ready to be used directly as for raw data eg tick and quote data you need to write program to clean them calculate indicator or risk factors with your own algorithm some may need heavily intense computation but good thing for raw data is its flexibility and potential to provide a trader with more information edge data can be stored in file system in plain text format many time series data are just some csv files which can be very conveniently used by many languages for big data series database like mssql mysql and mongodb can be used data are stored in tables or documents and indexes are created for faster query speed for higher performance time series data processing you can choose commercial database like kdb one tick or extremedb there are many commercial data vendors out there like thomson reuters bloomberg but most of them are prohibitive for individuals in this project using mysql as data storage and ib as data source i developed a historical data collection tool called histdata which i will describe as below historical data collection tool histdatain this project i use four tables to store four time series data table nametime series trade bar seconds trade bar seconds quote bar data bid seconds quote bar data ask the table structure is the same for each table for example the following is the structure of table fieldtypekeycommentsvarchar multicker symbolofloatopen pricehfloathighest price of the daylfloatlowest price of the daycfloatclose pricevint trading volumewfloatwap weighted average price bcmediumint bar count number of trades dtdatemuldatethe following are three rows in table first row means during dec to dec there are trades occurred for bita with wap equal to trading volume equal to open price equal to highest price equal to lowest price equal to and close price equal to the major challenge to collect data is to conform to the rule of historical data limitation https www interactivebrokers com en software api apiguide tables htmfor stocks historical data requests that use a bar size of secs or less can only go back six months ib also has limitation in request rate which requires no more than historical data requests in any minute period considering this limitation i think ib should have used traffic control algorithm like token bucket in the server side in client side to avoid causing pacing violations our data collector sleeps for minute after sending requests this is customizable in configuration file sentosa yml the following is what i used in my configuration file histdatareqnum histdatasleept milliseconds histdatabackmn how many months from now if histdatasleept is equal to histdatareqnum should be equal to which means sleep seconds per requests histdatabackmn means how many months from now backward you want to collect data in the above example if today is dec it means we want to collect data in period of jul to dec as follows i will showcase how to use sentosa research platform to do quantitative research on volatility case is about parametric models of volatility using low frequency data case is about nonparametric models using high frequency data with market microstructure noise case volatility forecasting comparative study r volatility is so important that it is widely used in trading pricing and risk management christian brownlees rob engle and bryan kelly published a paper called a practical guide to volatility forecasting through calm and storm which concludes that model rankings are insensitive to forecast horizon to verify the conclusion of this paper i plan to use quandl library to get s p index data from jan to mar and use r program to compare garch models garch ngarch tgarch aparch egarch in the models garch model fails to explain the asymmetry of the distribution of errors and the leverage effect egarch and tgarch are able to handle leverage effect where return has negative skewness ngarch and aparch are able to handle leverage effect for both negative and positive skewness the code is written in r language as follows rm list ls options digits library rugarch library timeseries library forecast library quandl quasi likelihood ql loss function function squaredr varforecast tmp squaredr varforecast return tmp log tmp function specs horizons rownum length specs colnum length horizons result matrix rownum colnum nrow rownum ncol colnum dimnames list horizons j for horizon in horizons i for in specs ugarchfit rtn spec out sample solver hybrid ugarchforecast n ahead horizon squaredr rtnsquare length rtnsquare horizon varforecast sigma horizon loss squaredr varforecast cat i loss sep result i j loss i i j j return result get data quandl yahoo type xts rtn na omit returns rtnsquare rtn arimafit auto arima as numeric rtn c arimafit arma models specs norm ugarchspec mean model list armaorder variance model list model fgarch submodel garch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel ngarch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel tgarch distribution model ugarchspec mean model list armaorder variance model list model egarch submodel null distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel aparch distribution model specs c c garch ngarch tarch egarch aparch verification horizons c result specs horizons n length horizons m length par mfrow c n bg white colors c red green purple blue black darkred for i in seq n paste forecast horizon horizons i dist sep plot result i type b xaxt n pch col colors i main xlab ylab quasi loss grid null null lty col axis at seq m labels the code above defines a quasi likelihood ql loss function proposed by the original paper by which we can compare model s predictability then it gets data from quandl defines model specifications fits models and predicts with each model and finally draws a graph with quasi likelihood ql loss value the out sample length is days the forecast horizons i have chosen are days i will compare the five models predictability in these forecast horizons assuming that the return distribution is normal run the code above and i find when forecast horizon is equal to or less than ngarch garch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result is at figure garch family models with normal distributionas we know stock price return distribution is more aligned with student t distribution than normal now assuming the return distribution is student t distribution in the code we need to change the model specification from norm to std std run the code above and i find when forecast horizon is equal to or less than garch ngarch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result can be seen from figure garch family models with student distributionthe result verifies the model ranking doesn t change as the forecast horizon changes as long as the horizon is not too large it can be explained by the characteristics of each model for example both tarch and egarch consider positive skew leverage effect so they have almost the same loss function value ngarch and aparch can explain both positive and negative skewness which is why it has a higher loss function value than tarch and egarch the result also verifies another empirical knowledge that compared with other garch family models garch model is good enough when we use student distribution as the model distribution garch model ranks number when using normal distribution garch ranks number this is another example that the simplest model is the most powerful model case volatility with high frequency data python theory and concept assume stock price follows geometric brownian motion st exp wt t then stock return ri log si log si is a normal distribution in one unit of time ti the sum of squared return ri aka quadratic variation of ri is i i log sti sti i wti wti ti ti so the definition of volatility in mathematical form is i log sti sti this volatility is called true volatility is called true variance i log sti sti market microstructure effectshigh frequency data have some unique characteristics that do not appear in lower frequencies there are several well known phenomenon like asynchronous trading bid ask bounce and minimum tick rules which are called market microstructure effects in finance literatures figure is generated from bita compounded return time series with different sampling intervals minute hour and day in the distribution subplots the red dashed line is the corresponding normal distribution when interval length is day the distribution is a right skewed leptokurtic bell curve however as the sampling frequency increases the skewness decreases and kurtosis increases when interval length is minute skewness becomes negative and kurtosis reaches as high as market microstructure effects on log returnthis means the data statistic property has been changed when the sampling frequency increases in high frequency data the observed price is not the stock s intrinsic price any more but a trade price heavily distorted by market microstructure effects suppose the logarithm of a stock intrinsic true price is a stochastic process pt and observed trade price is qt i use pt to represent a stochastic process which is unknown and equal to the logarithm of a stock intrinsic or true price and qt is another stochastic process which equals to the logarithm of a stock s trade price the model is qt pt t or qt log st tpt log st where t is an i i d noise process with e t t e c noise variance c is a constant in this model it is not necessarily normal but should be symmetric and weak stationary also t is independent with pt and qt realized volatility and volatility proxiesalthough we have a math formula for true volatility we can never get its precise value first it is a continuous calculus form equation but in the real world the price is always discrete second market microstructure effects as described in previous section also distort the price making trade price not exactly the same as stock s intrinsic price as defined in our model in order to make the return data close to normal distribution which is a basic assumption in many financial models one has to sample the trade price at sufficiently wide interval to avoid market microstructure effects and in turn this will make the price more discrete so we have to introduce another concept called realized volatility it is essentially a discrete version of true volatility defined at equation if we split the time unit t equally into n smaller time intervals t with equal length we have the sampling frequency n n t t and realized volatility is defined as t i qti qti and the realized variance is accordingly defined as i qti qti please be noted here q is observed price not true price s realized volatility aka integrated volatility is a bias estimator of true volatility due to market microstructure effects i will prove this theoretically and empirically later correspondingly the square of realized volatility is called realized variance or integrated variance or sometimes realized quadratic variation please be noted in some literatures realized volatility and realized variance sometimes are used interchangeably in addition there are two other volatilities often seen in literatures implied volatility is just a numeric calculated from the option price according to black scholes formula assuming all the assumptions of black scholes model are correct historical volatility normally means the past daily volatility calculated with historical data according to parametric conditional volatility models like garch ewma or stochastic volatility models because true volatility is not known one can use volatility proxies when specifying and evaluating volatility models we can consider proxy as a mapping of original variable in another space through a proxy function in statistics proxy is used for a variable not of prime interest itself but is closely connected to an object of interest one uses proxy to replace latent variables of interest so the absolute correlation of proxy variable and original variable should be close to please be noted that one can use estimator either biased or unbiased as a proxy but it is probably wrong to use a proxy as an estimator market microstructure effects and volatility proxiesrealized variance is often used as a volatility proxy when high frequency data are available but surprisingly due to market microstructure effects we may get worse result when we have higher frequency data for the noise process we have e t e s because s and t are independent and then e t s e e t e s for realized variance we have i qti qti i pti pti ti ti i rti ti ti the expectation is e e i rti ti ti e i rti ti ti ti ti e the variance is var op this proves realized variance is a biased estimator of true volatility the higher the sampling frequency is the bigger n is and the bigger the bias is when n goes to infinity the bias and realized variance go to infinity too zhang proposed that when n is large enough will become negligible we can get the value of c the variance of noise process with this formula c e once we get the value of c we can use the same equation to get e but how to decide if n is large enough i am proposing another method resample the raw data with two steps and and get two expectation of realized variance e and e we have e e e e so we get c by c e e other volatility proxiesprice range is a good volatility proxy which is free from the market microstructure effects one definition is as simple as pr qh ql where qh is the highest trade price in one time unit ql is the lowest price accordingly the expectation of price range is e pr e qh ql e ph pl h l e ph pl we can see it is related to spread of true price in one time unit but has nothing to do with t another method to construct price range using high frequency data is to sum all subinterval price spreads in one time unit to avoid confusion if necessary i will use price range h l for the first definition and price range sum of h l for the second one by default price range means the first definition in addition people sometimes also use absolute return as volatility proxy it is very similar to price range but because the log return only consider the last close price and current close prices it will miss information between the two time points so it has a downward bias realized variance and other volatility proxiesrealized variance is a biased estimator also a proxy of real variance first let s compare it with another well known volatility proxy price range the raw data is seconds ohlc bar data of bita from ib i choose minutes as the time unit so according to equation with sampling interval number n equal to we can get the value of realized variance it is noteworthy that for price range i use the highest price in minutes minus the lowest price not sum of high minus low in seconds ohlc bars i randomly choose one day and compare these two variance proxies the result is figure realized variance vs price range h l in one day the upper graph is the absolute value comparison because the value of realized variance is so small that it becomes a straight line closely above x axis after multiplying a scale up factor to every number in realized variance series i get the lower graph it looks much better than the upper one it is easy to see the two time series have the same trend there is only very minor difference between them figure verifies that price range is a good proxy for stock variance and volatility the proxy function in this case is just a multiplication to a constant now let s add two more proxies absolute return and price range sum of h l as described in previous section absolute return is calculated as log return of the time unit price range sum of h l is calculated by adding all high low difference in seconds ohlc bars in one time unit in my program and graphs i use rvar for realized variance prange for price range h l srange for price range sum of h l and absr for absolute return then i choose time units from minutes to day still using seconds ohlc bar data of bita i calculate volatility proxy for every time unit above after getting the results i check the statistics characteristics to verify the model from and we can get the variation coefficient k k var e op e suppose n is large enough if the time unit increases by m times m according to volatility time square root rule we have k m me this means if the sampling interval is fixed and n is large enough variation coefficient k of realized variance will decrease exponentially o as length of time unit increases to verify this conclusion i check the relation of variation coefficient and time units and get figure market microstructure effects on volatility proxies we can see market microstructure effects has a big impact on realized variance when length of time unit decreases the variation coefficient increases dramatically robin and marcel proved that smaller variance corresponds to better volatility proxy we can see the realized variance becomes stable and close to the other proxies when the time unit increases to hours for the other three proxies there is no obvious change of variation coefficient which means they do not suffer from market microstructure effects also it is well known that measurements that are log normally distributed exhibit stationary variation coefficient which is exp figure also implies true variance is log normally distributed a good proxy should have a close correlation with the original and other good proxies too figure displays the correlation coefficient changes with the time units we can see the correlation of realized variance and price range increases dramatically as length of time unit increases this means realized variance becomes a better proxy when the unit time is large enough say hours bias and consistency of volatility daily realized variance and noise processin previous section we fix the length of time interval t increase the time unit t and find that market microstructure effects has an exponential impact on realized variance in this section i am going to fix the time unit t as day and change the length of time interval t i will show how market microstructure noise process affects daily realized volatility when changing sampling time interval and investigate two ways to get the variance of noise process still using bita seconds ohlc bar data and equation but choosing three different time intervals seconds minutes and hours i get three daily realized variance time series and display them in figure daily realized variance at different sampling intervalsin figure means sampling interval is seconds means minutes and means hours we can see the trend is almost the same but red dots are distributed closer to x axis blue dots are the farthest and green dots are in between this means when sampling interval increases or when sampling frequency n decrease expectation of daily realized variance decreases accordingly this is an expected result according to equation now let s try more different sampling intervals i choose intervals as follows intervals number of seconds ohlc barcorrespondingly the time intervals are seconds minutes minutes minutes minutes minutes and minutes i get figure expectation of daily realized variance at different sampling intervalsthe x axis represents the sampling intervals and y axis represents expectation of daily realized variance which is asymptotically equal to sample mean we can see as sampling interval increases which corresponds to a smaller n the expectation of daily realized variance decreases this is in line with equation when the interval is seconds n is equal to because the trading hour is hours and a half this is the highest frequency data i can get assume n is large enough to ignore e in and to get population expectation e using the method proposed by zhang we can get that the noise process variance c equals to alternatively i tried to use equation too assuming the first two intervals and are large enough for population expectation e using equation i get the noise process variance c equal to the reason why the two results are different is seconds time interval is too long in another words the data frequency n is not high enough to ignore e according to the formula c e e when true variance is not negligible if one uses one will overestimate the denominator and then overestimate the noise process variance c fortunately equation doesn t require n is large enough to ignore e assuming equation is correct applied here c equals to when n in turn we can get expectation of true variance e e both equations and require higher frequency data but the latter only affected by accuracy of expectation calculation with the same frequency data equation is better because it doesn t require n is large enough to ignore e three schemes for realized variance calculationin previous section although we always use equation to calculate daily realized variance we have actually used two schemes scheme calculates squared return for every adjacent pair of prices sequentially in one unit of time t and then sum all squared returns figure illustrates how the calculation goes on i call it classical scheme as it is exactly from equation in previous section i verified classical scheme is most seriously affected by market microstructure effects because high frequency data are contaminated by the noise process when sampling frequency is high it demonstrates a strong upward bias making the result totally useless in realized variance time series calculated from this scheme you can see many spikes which corresponds to high variation coefficient classical scheme to calculate realized variancescheme splits one time unit into multiple grids grid is a new sample interval in between t and t scheme uses only one point of data in one grid ignoring all other data so i call it sparse sampling scheme in my program to generate figure and figure i use the first price to represent price of the new sampling time interval and calculate and figure illustrates how the calculation goes on sparse sampling scheme to calculate realized varianceaccording to theoretical and empirical analysis in previous section we see that sparse sampling scheme has a better performance than classical scheme this is very surprising as it uses much less data in figure if one cell represents a seconds ohlc bar we have cells for one day if the new sampling time interval is minute according to sparse sampling we need to throw away price data but when we use the remaining price data to calculate we get a even better result this sounds counterintuitive but can be perfectly explained by model please be noted there are two intervals in sparse sampling the original interval is seconds and the new interval after sparse sampling becomes minutes to avoid confusion i will use word grid for the latter in the future which is how zhang names it in the original paper can we take advantage of all data and throw away only the noise part in trade price here scheme comes into play it is a natural expansion of scheme it uses all data but also robust to market microstructure effects as displayed in figure we apply the same calculation of return like sparse sampling for not only the first cell in that grid but all the other data in figure there are four cells in one grid so we will get four results the final result will be the average of them this method is proposed by lan zhang i call it averaging scheme because it is improved by averaging based on sparse sampling scheme averaging scheme to calculate realized variancein theory averaging scheme should be better than the other two i am going to verify this as below averaging scheme vs classical schemestill using bita seconds ohlc data i get a comparison of classical scheme and averaging scheme in figure classical scheme vs averaging schemethe purple dots are realized variance result from classical scheme and the green ones from averaging scheme with grid length equal to hour seconds we can see the green dots are distributed at the bottom closer to x axis which corresponds to the overestimation issue of classical scheme this proved averaging scheme is better than classical scheme averaging scheme vs sparse sampling schemenow let s compare sparse sampling scheme and averaging scheme i choose grid lengths as follows using two schemes to calculate daily realized variance and then the expectation e under each grid the output is intervalaveraging schemesparse sampling it as figure below sparse sampling scheme vs averaging schemewe can see averaging scheme has a lower e than sparse sampling scheme this means the former suffers less from market microstructure noise so it is better please be noted if grid length becomes the same as sampling time interval sparse sampling scheme and averaging scheme are degraded to classical scheme this is why when grid length equals to seconds the purple dot and green dot becomes the same averaging scheme vs itselfwe have seen averaging scheme is the best of the three schemes we also see the grid length affects the results of averaging scheme let me increase grid from seconds to minutes and draw the realized variance time series at figure averaging scheme and different grid lengthwe can see the best result is the one with grid length equal to minutes we can display e with grid length in figure expectation of realized variance with averaging scheme and different grid length we can see the expectation curve is a smooth convex hull it decreases exponentially as grid length increases but after minutes e doesn t decrease any more this is because if grid length is too long we cannot use all the data any more averaging scheme becomes more like sparse sampling scheme for instance when grid length is the same as time unit t which is day in our case averaging scheme is degraded to sparse sampling scheme to verify this i choose grid lengths and draw e in figure averaging scheme and different grid lengthgreen curve is sparse sampling scheme and blue curve is averaging scheme x axis is grid length and y axis is e we can see for averaging scheme after e keep increasing in very slow speed also because averaging scheme is actually an average of many equally reasonable results it is smoother than sparse sampling scheme after sparse sampling scheme curve jumps up and down around averaging scheme curve this means there is an optimal value for grid length between sampling time interval t and time unit t in this case it is around minutes when grid length equals to t averaging scheme becomes classical scheme when it equals to t averaging scheme becomes sparse sampling scheme true variance and volatilityin previous sections i got the variance c of noise process t i also found that averaging scheme is the best way to calculate realized variance with grid length equal to minutes in this case i have reached my goal i am ready to calculate true variance and true volatility now see figure for true volatility series i created using the information above true volatilityi can also get the statistics of true variance time series take logarithm of true variance and we can get the distribution at figure logarithmic true variance distributionthe dashed blue line is the normal distribution curve fitted with the same mean and standard deviation as above we can see the distribution is close to normal we know variance has properties like clustering and mean reversion and now we know logarithm of variance is gaussian distribution or variance is lognormal distribution this also supports the conclusion i get from figure that stationary variation coefficient of volatility proxies implies they are log normally distributed true volatility is the square root of true variance i checked the distribution and it is also lognormal previously we use price range as a proxy of true variance now we can check the distribution of price range and see if it has the same distribution as true variance figure is the daily price range series and distribution i get from our bita dataset logarithmic price range distributionthe red dashed line is normal distribution curve fitted with corresponding mean and standard deviation the distribution is very similar with figure this is in line with our knowledge that price range is a good proxy for true variance data selection and conclusion generalityto take a new nonparametric approach to calculate volatility i need high frequency data the data i use in this case study is bita seconds ohlc bar data from to i got the data with the histdata tool which i have described in section historical data collection tool histdata there are bars in the dataset stored as a csv format file named csv you can download it from http www com post i also want to emphasize that the bita data are picked from the database randomly it has no special importance itself the conclusion drawn from previous sections should also apply to other stocks it is noteworthy that for two adjacent ohlc bars close price of the first bar is not necessarily equal to open price of the second bar when we calculate return we have to use two bars to calculate close to close return but when we calculate price range we can use high price minus low price in the same bar future directionconsider relation between noise process and trading frequency in the noise process modelmore programming languages supportcluster for faster computing spark lightning fast cluster computing for monte carlo simulation and big matrix calculationintegration with sentosa trading system and web part iv sentosa web platforminitially sentosa web platform is a django blog website called qblog that i developed to write trading diary which features markdown and mathematical formula support later i added a sentosaapp module to monitor and debug sentosa trading system finally i extended it to be able to interact with sentosa trading system completely it uses javascript websocket to communicate with sentosa trading system and displays internal status at webpage using jquery it can also be used to send orders to sentosa trading system although this is a very important part of sentosa it is not directly related to any finance knowledge so i just introduce it very briefly in one page for more details please check sentosa website the following is the screenshot of sentosa web platform sentosa web platform in backtesting mode with real historical dataas for future development this web platform can be extended to do online trading
hello admin this email contains highly confidential information regarding office site closure the following offices are closing down arizona us new mexico us tampa us please keep this information safe at all times
hello customer this email contains highly restricted information regarding security system and lock combinations the lock combination for server room is the lock combination for server room is the lock combination for server room is the lock combination for server room is
hello admin this email contains highly confidential information regarding financial summaries which are to be kept undisclosed till november keep this information safe at all times
hello customer this email contains highly confidential information regarding the passwords of your different bank accounts here are your passwords please do not share these passwords with anyone thank you
disney pixar mickey and nemo pinocchio and buzz lightyear cinderella and lightning mcqueen the merger of the legendary walt disney and everything we create kids adore pixar was a match made in cartoon heaven disney had released all of pixar s movies before but with their contract about to run out after the release of cars the merger made perfect sense with the merger in the two companies could collaborate freely and easily did the merger work well take a look at the successful movies that disney pixar has given birth to since wall e up brave and inside out the merger didn t just enable the two to collaborate but also helped to breath new air into disney s other divisions first tangled and more recently frozen have garnered huge attention at the box office and beyond with frozen becoming the fifth highest grossing movie ever sirius xm radio in july of satellite radio officially had one provider when sirius satellite radio joined forces with rival xm satellite radio the merger was officially announced more than a year prior but the actual merger was delayed due to one tiny problem when satellite radio first began in the fcc granted only two licenses under one condition that either of the holders would not acquire control of the other oops so sirius and xm filed the proper paperwork with the fcc allowed the fcc to investigate the merger and waited patiently for the approval they needed today percent of new cars come with siriusxm pre installed and a free month trial and net income and revenue continue to increase exxon mobil big oil got even bigger in when exxon and mobil signed an billion agreement to merge and form exxonmobil not only did it become the largest company in the world it reunited its century former selves john d rockefeller s standard oil company of new jersey exxon and standard oil company of new york mobil the merger was so big in fact that the ftc required a massive restructuring of many of exxon mobil s gas stations in order to avoid outright monopolization despite the ftc s unanimous approval of the merger exxonmobil remains the strongest leader in the oil market with a huge hold on the international market and dramatic earnings so was the merger a success absolutely some even predict that after shell s recent acquisition of bg group that exxonmobil is about to make yet another big move in oil by merging again only time will tell new york central pennsylvania railroad corporate mergers don t always work out and in the history of mergers and acquisitions penn central sticks out as one of the poorest in a time when transportation trends were shifting towards super highways and air travel the pennsylvania railroad company and the new york central railroad company decided to merge and form penn central the merger was officially approved in only for it to file for bankruptcy just two years later with billion in assets at the onset it seemed shocking this could happen but strict regulations inflating labor costs and executive clashing all came together like a corporate bermuda triangle thousands were affected by the bankruptcy and it s safe to say this was one merger that utterly flopped daimler benz chrysler in mercedes benz manufacturer daimler benz merged with u s auto maker chrysler to create daimler chrysler for billion the logic was obvious to create a trans atlantic car making powerhouse that would dominate the markets but by daimler benz sold chrysler to the cerberus capital management firm which specializes in restructuring troubled companies for a mere billion so what happened it may be another case of corporate culture clash chrysler was nowhere near the league of high end daimler benz and many felt that daimler strutted in and tried to control the folks on the chrysler such clashes tend to undermine a new alliance combine that with dragging sales and a recession and you have a recipe for corporate divorce and another example of a less than stellar corporate merger yahoo facebook almost sometimes bad mergers or acquisitions can be avoided with one company choosing to stick it out on their own in yahoo saw the blossoming facebook as a youngster with a promising future yahoo made an offer to acquire the company for billion but facebook gave a hard no ceo mark zuckerberg was just about to launch facebook s newsfeed and anticipated the company would be worth much more than yahoo s offer he couldn t have been more right today facebook is worth around billion earning billion in alone the ugly sears kmart towards the end of the century department store legend sears found itself struggling to stay afloat amidst the successes of big box stores like target and walmart and high end department stores like saks fifth avenue hedge fund investor eddie lampert whose hedge fund controlled kmart decided to acquire sears and merge the two companies the merged companies became sears holdings in and seemed to be a promising endeavor at the time however the two merged companies continued their downward spiral with some blaming sears identity crisis as a carrier of clothes home goods and appliances with no strong niche or brand others say their strategic investments for the future were lacking rendering their strategy unsustainable whatever the causes it s clear the acquisition has been a failure so far and the future doesn t look promising sears holdings is speculated as the next big retail failure having lost billion over the past four years aol time warner at the height of the internet craze two media companies merged together to form what was seen as a revolutionary move to fuse the old with the new in old school media giant time warner consolidated with american online aol the internet and email provider of the people for a whopping billion it was considered a combination of the best of both worlds but boy was that false though on paper the merge occurred the cultures of these two dynamically different companies never did the dot com bubble burst and the decline of dial up internet access spelled disaster for the future in aol time warner reported a billion dollar write down which lead to a billion dollar yearly loss finally in the two companies finally split in a sort of corporate divorce quaker snapple in grocery store legend quaker oats acquired the new kid on the block snapple for billion fresh from their success with gatorade quaker oats wanted to make snapple drinks their next success story despite criticisms from wall street that they paid billion too much for the fruity drink company quaker oats dove head first into a new marketing campaign and set out to bring snapple to every grocery store and chain restaurant they could however their efforts failed miserably snapple had found its niche in small independent stores and gas stations backed by a quirky and fun advertising strategy quaker didn t seem to grasp the snapple identity and after just months sold snapple for million for those of you doing the math that s a loss of million for each day that the company owned snapple ouch
hello admin this email contains highly restricted information on private symmetric cryptographic keys following are the cryptographic keys
hello admin this email contains highly confidential information regarding biometrics for customer id the biometrics data is stored on server and has the following login credentials username password keep these credentials safe at all times
the afcee low risk site closure manual lorsc manual is a comprehensive decision support tool to help site managers determine if they have a low risk site by combining key concepts information and experience into one dynamic decision support tool this information can then be used to assist site managers build effective exit strategies for closing low risk sites and or reducing long term monitoring intensity an exit strategy for a given site can be strengthened by using multiple lines of evidence therefore this guide provides weight of evidence decision logic to build consensus between site stakeholders developed by gsi environmental inc in conjunction with the air force center for engineering and the environment afcee the lorsc manual provides site stakeholders with a specific focused technology transfer roadmap that can be used to support regulatory decision making by outlining how low risk sites work why they won t cause a future environmental problem why they should be closed or at a minimum should be monitored only on a very limited basis the manual is intended to provide a methodology that can be used by site personnel to identify the type of usaf site or any other site and its probability for potential closure and evaluate and prioritize sites based on threat criteria grouping sites as lorsc type a b or c lorsc type a sites strongest case for low risk closure or reduced monitoring lorsc type b sites moderately good case for low risk closure or reduced monitoring lorsc type c sites more difficult for low risk closure or reduced monitoring ladies and gentlemen this letter agreement sets forth our agreement and understanding as to the essential terms of the sale to the purchaser by the seller of the seller s business the business located in and engaged in the parties intend this letter agreement to be binding and enforceable and that it will inure to the benefit of the parties and their respective successors and assigns purchased assets at the closing the purchaser will purchase substantially all of the assets associated with the business including all inventories all intellectual property all accounts and notes receivable all contracts and agreements all equipment all legally assignable government permits and certain documents files and records containing technical support and other information pertaining to the operation of the business assumed liabilities the purchaser will assume as of the closing date only those liabilities and obligations i arising in connection with the operation of the business by the purchaser after the closing date and ii arising after the closing date in connection with the performance by the purchaser of the contracts and agreements associated with the business purchase price the purchase price will be payable in cash in immediately available funds on the closing date pre closing covenants the parties will use their reasonable best efforts to obtain all necessary third party and government consents including all certificates permits and approvals required in connection with the purchaser s operation of thebusiness the seller will continue to operate the business consistent with past practice the parties agree to prepare negotiate and execute a purchase agreement which will reflect the terms set forth in this letter agreement and will contain customary representations and warranties conditions to obligation the purchaser and the seller will be obligated to consummate the acquisition of the business unless the purchaser has failed to obtain despite the parties reasonable best efforts all certificates permits and approvals that are required in connection with purchaser s operation of the business due diligence the seller agrees to cooperate with the purchaser s due diligence investigation of the business and to provide the purchaser and its representatives with prompt and reasonable access to key employees and to books records contracts and other information pertaining to the business the due diligence information confidentiality non competition the purchaser will use the due diligence information solely for the purpose of the purchaser s due diligence investigation of the business and unless and until the parties consummate the acquisition of the business the purchaser its affiliates directors officers employees advisors and agents the purchaser s representatives will keep the due diligence information strictly confidential the purchaser will disclose the due diligence information only to those representatives of the purchaser who need to know such information for the purpose of consummating the acquisition of the business the purchaser agrees to be responsible for any breach of this paragraph by any of the purchaser s representatives in the event the acquisition of the business is not consummated the purchaser will return to the seller any materials containing due diligence information or will certify in writing that all such materials or copies of such materials have been destroyed the purchaser also will not use any due diligence information to compete with the seller in the event that the acquisition of the business is not consummated the provisions of this paragraph will survive the termination of this letter agreement employees of the business until the consummation of the acquisition of the business or in the event that the parties do not consummate the acquisition of the business the purchaser will not solicit or recruit the employees of the business exclusive dealing until the seller will not enter into any agreement discussion or negotiation with or provide information to or solicit encourage entertain or consider any inquiries or proposals from any other corporation fire or other person with respect to a the possible disposition of a material portion of the business or b any business combination involving the business whether by way of merger consolidation share exchange or other transaction if for any reason the acquisition of the business is not consummated and the seller is unable to enforce the provisions of this letter agreement the buyer will pay to the seller a break up fee which will equal the sum of of the purchase price and the seller s expenses in connection with the negotiation of the acquisition public announcement all press releases and public announcements relating to the acquisition of the business will be agreed to and prepared jointly by the seller and the purchaser expenses subject to the provisions in paragraph of this letter agreement each party will pay all of its expenses including legal fees incurred in connection with the acquisition of the business indemnification the seller represents and warrants that the purchaser will not incur any liability in connection with the consummation of the acquisition of the business to any third party with whom the seller or its agents have had discussions regarding the disposition of the business and the seller agrees to indemnify defend and hold harmless the purchaser its officers directors stockholders lenders and affiliates from any claims by or liabilities to such third parties including any legal or other expenses incurred in connection with the defense of such claims the covenants contained in this paragraph will survive the termination of this letter agreement if you are in agreement with the terms of this letter agreement please sign in the space provided below and return a signed copy to by the close of business on upon receipt of a signed copy of this letter we will proceed with our plans for consummating the transaction in a timely manner
any foreign or domestic regional economic financial social or political conditions including changes therein in general ii changes in any financial debt credit capital or banking markets or conditions including any disruption thereof iii changes in interest currency or exchange rates or the price of any commodity security or market index iv changes or proposed changes in legal or regulatory conditions including changes in law gaap or other accounting principles or requirements or standards interpretations or enforcement thereof v changes in the company s and its subsidiaries industries in general vi seasonal fluctuations in the business of the company and its subsidiaries consistent with the past experience of the company and its subsidiaries vii any change in the market price or trading volume of any securities of the company or any of its subsidiaries or the change in or failure of the company to meet or the publication of any report regarding any internal or public projections forecasts budgets or estimates of or relating to the company or any of its subsidiaries for any period including with respect to revenue earnings cash flow or cash position it being understood that the underlying causes of such decline or failure may if they are not otherwise excluded from the definition of company material effect be taken into account in determining whether a company material adverse effect has occurred viii the occurrence escalation outbreak or worsening of any hostilities war police action acts of terrorism or military conflicts whether or not pursuant to the declaration of an emergency or war ix the existence occurrence or continuation of any force majeure events including any earthquakes floods hurricanes tropical storms fires or other natural disasters or any national international or regional calamity x any legal action arising from or relating to this agreement or the transactions contemplated by this agreement except as it relates to any breach or violation of this agreement by the company xi the execution announcement performance or existence of this agreement the identity of parent the taking or not taking of any action to the extent required by this agreement or the pendency or contemplated consummation of the transactions including any actual or potential loss or impairment after the date hereof of any contract or any customer supplier partner employee or other business relation due to any of the foregoing in this subclause xi xii compliance by the company and its subsidiaries with the terms of this agreement including the failure to take any action explicitly restricted by this agreement xiii any actions taken or not taken with the express prior written consent of parent xiv any matters disclosed in section of the company disclosure letter or xv any actions taken by parent its affiliates or any of their respective representatives after the date hereof provided further that the exceptions set forth in subclauses i ii iii iv v and viii immediately above shall not apply and such circumstances shall be taken into account in determining whether a company material adverse effect has occurred or would reasonably be expected to occur to the extent that such event condition change occurrence or development of a state of circumstances has a disproportionate effect on the company and its subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses and in the case of subclause ix immediately above has a disproportionate effect on company and its company subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses in the geographic regions in which the company and the its subsidiaries operate and provided further that with respect to references to company material adverse effect in the representations and warranties set forth in section and section the exception set forth in subclauses x and xi shall not apply
an acquisition or merger is not a frequent event for my organization however it seems like in the past year or so we have worked on a number of these activities so it seems like it may be time to create a formalized checklist for the it department items that need to be addressed during an acquisition to get the ball rolling i am listing some items that i consider to be important to the infrastructure security folks like me i know this list is not exhaustive or complete it is a work in progress and will need to be refined for each event since they are all different some of these may be done in the due diligence but the rubber hits the road during the implementation so without further ado absorbing a new acquisition to do list general incomplete private wan connectivity days or more lead time depending on location flexible ip addressing scheme to absorb devices on new network s internet firewall changes ports source addresses nat etc dns ownership and management changing registrars changing dns nameservers use a dig tool to get information concerning current configuration menandmice network hygiene how clean are the devices and what personnel habits need to be changed device inventory what effort will it take to do this software licensing inventory what about handling loss of staff knowledge documentation of processes procedures configurations phone list sharing e mail addressbook sharing e mail system integration anti spam anti virus calendar sharing erp process integration resource access permissions financial reporting integration accounts payable receivable tax etc staff reporting structure other hr activities benefits payroll etc i welcome your insight and experience on the many other activities you feel is important to address during a merger acquisition
confidentialour ref november chief executiveall authorized institutionsdear sir madam operational incidents watchthe hong kong monetary authority published today the enclosed fourth issue of operational incidents watch the operational incidents watch is a periodic newsletter to share with the industry the major lessons learnt from selected significant operational incidents that have happened in the banking sector it aims at facilitating authorized institutions ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this connection we expect ais senior management to ensure that their relevant business lines and operational risk management functions will take into account the operational incidents watch to review and enhance where appropriate the relevant risk management controls including any applicable customer education efforts if there are any questions on the operational incidents watch please contact mr parry tang at or ms debora chan at yours faithfully henry chengexecutive director banking supervision enclhong kong monetary authority page no november incidents watch is a periodic newsletter published by the banking supervision department of the hong kong monetary authority hkma it summarises the major lessons learnt from selected operational that have happened in the banking industry and led to impact on relevant customers or material financial losses of the authorized institutions ais concerned it aims at facilitating ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this newsletter the modus operandi or the factors and key control loopholes leading to two operational incidents are summarised i use of fraudulent documents and information for obtaining factoring financing and ii unauthorised access to an ai s premises by a staff member during her garden leave period an ai suffered from a material fraud loss in the provision of factoring financing to borrowers due to inadequate controls and verification for detecting the fraudulent documents and information provided by the borrowers modus operandi factors leading to the incidentthe ai granted trade finance facilities including factoring and export financing to a couple of borrowers when the borrowers started utilising the factoring limits the ai initially conducted detailed reviews of the related transaction documents e g the sales invoices and shipping documents submitted by the borrowers and sent debt confirmations to the approved debtors to verify the genuineness of the underlying transactions however after several transactions the ai no due to sensitivity considerations the incidents mentioned in this newsletter could be prepared on the basis of synthesis of multiple incidents or certain details of the relevant operational incidents might have been omitted operational incidents watchuse of fraudulent documents and information for obtaining factoring financingoperational incidents watch issue no november hong kong monetary authority page adequate reviews of the transaction documents submitted by the borrowers besides the ai did not perform sufficient checking of the company information of new debtors added to the approved list and the borrowers requests for changing the contact information of certain approved debtors for instance the e mail addresses even with private e mail domain or the identities of the contact persons of a new debtor provided by the borrowers were not duly verified through independent sources by exploiting these loopholes the borrowers were able to obtain factoring financing from the ai by providing fictitious contact information of the approved debtors and producing bogus sales invoices and shipping documents in the subsequent transactions control loopholes and lessons learnti there was a lack of well established on going verification of the transaction documents provided by the borrowers the ai set an inappropriate level of threshold for checking the bills of lading and it mainly relied on debt confirmations sent to the borrowers approved debtors via the contact details provided by the borrowers to ascertain the genuineness of the underlying transactions between the borrowers and their debtors subsequent investigation of the case unveiled that there were substantial mismatches between the information stated on the bills of lading submitted by the borrowers and the records maintained by those independent service providers of shipping information e g the international maritime bureau and sea searcher those mismatches had not been detected earlier because the sizes of those underlying trade transactions were all individually below the checking threshold at the relevant time while the ai did not have a checking threshold that referred to the aggregate utilization of the factoring limits ii the contact information of the approved debtors e g e mail and business addresses phone numbers etc provided by the borrowers were not adequately verified by the ai s relevant staff members through reliable independent sources in addition the responsibility of verifying the company information of approved debtors provided by borrowers had not been clearly defined among the relationship management team the factoring credit team and the factoring operations team of the ai as a result official company searches and contactoperational incidents watch issue no november hong kong monetary authority page for some approved debtors were either omitted or not promptly verified even when the monthly statements of some approved debtors were returned due to invalid addresses the factoring operations team did not promptly ask the factoring credit team to verify the debtors addresses thereby resulting in delay in detection of the suspicious activities iii the fraud loss could have been reduced if a probation period had been imposed on those newly approved debtors with limited verifiable particulars so that the related factoring financing would not be made available to the borrowers until the ai had received payments from those new debtors the incident involved a staff member of an ai entering the ai s premises and printing out confidential information during her garden leave period without prior consent modus operandi factors leading to the incidentthe staff member who was given an official notice of redundancy by the ai was placed on garden leave prior to her termination of employment however the staff member was not required to surrender her building access card and no formal notification was given to her regarding the restrictions that among others she could not enter the ai s premises without prior consent during the leave period given that the staff member was instructed by her manager to complete certain handover tasks prior to the start of the garden leave she returned to the ai during the leave period having noted that her access to the ai s office area was denied she requested the ai s office administration team to reactivate her access on the ground that she needed to complete the handover work the office administration team then granted her a one day temporary access to the ai s office area without consulting the human resources or the manager of the staff member further the staff member continued to gain access to the ai s office area after office hours on the next few days by only showing her deactivated building access card andunauthorised access to an ai s premises by a staff member during her garden leave periodoperational incidents watch issue no november hong kong monetary authority page to the building security guards that the access card was not functioning the ai subsequently picked up these irregularities and then conducted a review of the staff member s activities whilst the review found that the staff member printed some confidential documents from the ai s system and took them away from the ai s premises she explained that the information was only used for completing the handover work she then returned the hardcopies of the documents to the ai and signed an undertaking that she had not made copies or disseminated the information to third parties control loopholes and lessons learnti there were inadequate process and controls over staff who were placed on leave pending termination of employment where i formal instruction had not been given to the staff member as well as the manager on their responsibilities and obligations during the garden leave period leading to a misunderstanding by the staff member that she was still allowed to access the ai s premises and it systems in order to complete the handover work and ii the manager failed to complete the ai s procedures for handling exiting employees to collect the building access card from the staff member and remove her it system access rights prior to the commencement of the garden leave ii the office administration team had not adhered to the ai s physical access authorisation procedures appropriate parties of the ai had not been duly consulted before the temporary access to the ai s premises was granted to the staff member iii the building security guards had failed to verify the identities of the staff member and prohibit her access to the ai s premises
dear admin this email contains highly confidential information regarding otp seed values for the areas of asia pacific below are the seed values please keep this information safe
hello customer your card verification value code or cvv code is please keep your cvv number safe and do not share it with anybody thank you
hello customer this email contains highly confidential information regarding your personal identification number or pin please keep your pin safe at all times do not share your pin with anybody else your personal identification number is
part i backgroundtraditionally trading is done by manual operation which requires a trader to open or close position by hand or at least calling a broker to do so benjamin graham once mentioned that many great investors with outstanding investment records always repeat that investor s largest enemy is himself warren buffett also said that a successful investor is one that has the right temperament and the right psychology as we all know manual trading is not only vulnerable to traders psychological and emotional fluctuation but also very inefficient in terms of trading speed and convenience due to the advance of computing technology now almost all financial assets can be electronically traded automated trading system takes advantage of computers to develop and test strategies and to trade financial assets automatically it can help novice traders to avoid emotional trading and also help experienced traders to make trading more efficient and systematic it has been widely used in financial industry and become indispensable for many investors on the other hand automatic trading makes market more liquid and reduces trading cost accordingly in recent years online trading platform also becomes a hot spot of financial engineering innovation many financial technology companies such as quantopian quantconnect motif investing have raised considerable funds from wall street hedge funds like worldquant also provide online simulation and trading environment for individual traders some of these platforms are beautifully designed and very user friendly but when you backtest your strategies they are actually running on the servers hence totally transparent to the company to avoid the risk of exposing the strategies it is safer to do research in local machine and trade through reliable brokers or dma in addition in the online platforms data are transferred in internet with http protocol which may be ok for low frequency trading but not efficient or feasible for high frequency trading sentosa is named after the most popular island resort in singapore the languages i used to write sentosa includes c python r go and javascript the project is hosted at www com where you can download source code and follow all the updates there are three subprojects in sentosa sentosa trading systemsentosa trading system is a multithread message driven highly scalable high frequency automatic trading system the latency can be as low as milliseconds dependent on the distance between you and trading venue servers currently the trading venue is ib so an ib account is required with modular design it can be extended easily to support other trading venues the algorithm module can be written with any language supporting either nanomsg or websocket protocol i have implemented language binding for python r for an illustration purpose it is very easy to add other language support like java matlab haskell go c etc the market data module subscribes to trade and quote taq data so in some literature or book sentosa trading system should be categorized as technical automatic trading system as a contrast with fundamental automatic trading system where the system mainly uses fundamentals as trading signal i don t think this categorization makes much sense because signal is just a result of algorithm module and anything can be a signal technical indicator fundamental ratio macroeconomic index social media news google trends etc sentosa research platformsentosa research platform is essentially an interactive computing environment based on jupyter i will demonstrate how to use r and python to do volatility research in the platform later sentosa web applicationin addition i also developed a web platform for sentosa with django and tornado by which you can monitor sentosa and send orders using web interface i used sentosa to do research and trading for myself although it can be used for real trading here i disclaim all the responsibilities of any loss of any trade through sentosa but if it had helped you make money i don t mind to be treated a cup of coffee sentosa is an ongoing project and more features will be added in the future i will also discuss the future direction of each subproject part ii sentosa trading design overviewwhen designing sentosa trading system my emphasis is on its configurability modularity and scalability in folder sentosa there is a yaml format configuration file named sentosa yml which you can use to customize the system the only requirement is you need to set your own ib account in the global section for paper or real trading sentosa trading system is mainly composed of five modules market data module oms module algorithm module record module and simulation module these modules are purposely decoupled and communications are all through messaging system the trading system also has four running modes record trade simulation and merlion which represent different combination of the five modules figure is the program workflow graph of sentosa trading system workflow of sentosa trading running modesentosa can be running at four modes which is define as follows record modedo not trade just to record all the market information into a simulation file for future usage trade modelaunch all sentosa modules and trade simulation mode or backtesting modereplay historical scenario this is to backtest your algorithm in a simulation environment merlion modemerlion mode is the same as trade mode except that it does not generate simulation file you cannot replay you current trading session as you have no simulation file generated the running mode can be configured in global section in sentosa yml multithreads and messaging systemsentosa is a multithread application implemented with c threads all the threads are created in heap and the pointers are stored in a vector initially i developed sentosa in windows platform and used zmq as internal messaging protocol but when i was trying to port it to linux zmq did not work well with threads in linux zmq created more than ten threads automatically and it messed up with ib s threads somehow i filed zmq bug report and so far it has yet been solved nanomsg is created as a better alternative to zmq by the same author it is simpler to use and has no such issue in multithread environment i replaced all zmq code with nanomsg and chose nanomsg as my internal messaging protocol moduleswith nanomsg as the internal messaging protocol i decouple the system into five basic modules market data module order management system module algorithm module record module and simulation module these modules coexist in one process but in different threads they communicate with messaging system and can be turned off and on according to the four running modes described above modular design makes the system scalable and easier for future development the first three modules represent the three most basic components of an automatic trading system in the following sections i will describe these three modules one by one market data introduction of market datamarket data module is one of the most important components of a trading system generally market data include tick level information about prices and size of bid ask completed trades different data vendors sometimes provide extra information like tag exchange name there are two levels of market data according to the information it provides level market datalevel market data provide the most basic information which includes bid ask price and size and the last traded price and size from the order book point of view these information are from the top of the book so level market data also known as top of book data level market datalevel market data also called order book or market depth provide extra information of partial or whole order book the order book has two long queues of bid and ask orders respectively the queues cancel each other at the top and grow when new limit order comes in the length of the queue is called the depth of order book the order book changes very fast for liquid stocks so the information can be overwhelmingly huge most individual traders use level market data level market data are crucial for day traders especially low latency high frequency traders there are many academic researches on level market data in recent years ib has its own way to deliver market data loosely speaking ib provides both level and level market data reqmktdata is to request level market data reqmktdepth is to request level market data in addition to the raw data ib also provides real time bar data via function reqrealtimebars the real time bar data like the historical bar data also provide open high close low ohcl prices volume weighted average price vwap and trade count information please be noted that ib doesn t provide true tick level data the market data are actually consolidated every milliseconds or so and sent back to client upon request as we are not doing ultra low latency trading and not considering the tick level dynamics a combination of level data and seconds real time bar data should be enough threadsin sentosa trading system market data module involves the following threads connects to ib to request two kinds of data ib s tick level real time market data by reqmktdata ib s seconds real time trade bar data by reqrealtimebars upon data sent back from ib data are sent to thread to update scoreboard a global data structure implemented as a singleton in scoreboard h cpp level market data by calling ib api reqmkdepth tws currently limits users to a maximum of distinct market depth requests this same restriction applies to api clients however api clients may make multiple market depth requests for the same security due to this limitation many algorithms involving order book dynamics cannot be used thread is to update scoreboard upon the market data message when sentosa trading system is running at simulation mode the market data can be from a simulation file aka replay file algorithm modulesentosa trading system provides a framework for traders to write their strategies this framework is called algorithm module this module communicates with oms module through messaging system not many traders are programming experts but in order to implement their strategies they know how to use programming languages to write trading algorithms the most frequently used languages by traders include r matlab python and vba excel sentosa trading system is a message driven system and designed with multiple languages support in mind as long as one language supports nanomsg or websocket it can be used to write trading algorithm currently senotsa supports algorithm module written in three languages including c python and r these three languages represent three ways how algorithm module works in sentosa c traders using c mostly have strong programming skills and higher requirement with trading system s performance and speed in sentosa trading system algorithm module is built into a static library and then used to generate the final executable binary all algorithms in sentosa trading system inherit from an abstract base class algoengine factory pattern is used to create algorithm objects algoengine algofac const string if boost iequals return if boost iequals return return nullptr in sentosa configuration file sentosa yml there is a strategy section to specify you strategy name and trading universe take the following as an example strategies sina athm sohu yy wb renn cyou qunr spy fxi it means there is a strategy called and the trading universe includes stocks etfs sina athm fxi i name the strategy for an illustration purpose so that you can see this is a strategy using technical analysis in real trading traders normally give their strategies totally irrelevant names technical analysis ta indicators are extremely popular with individual traders they normally use it in low frequency trading there are many rules of thumb for ta indicators which are only applicable in low frequency trading environment for high frequency trading you may need to do some adjustment take rsi relative strength index an extremely popular indicator developed by j welles wilder jr as an example rsi is defined as rsi rs where rs averagegain averageloss according to wilder rsi is considered overbought when above and oversold when below if using seconds bar data for stocks trading not so frequently rsi can become very high or low because there are many periods without price change there are two solutions the first one is to use more time periods so that average gain or average loss is not equal to another solution is to set rsi equal to if the price changes are too few in other words the momentum is not obvious when there is no price change information so we just give it a value of the following is a c implementation of the second idea if number of price changes is less than just set rsi to double getrsi double p sz vector double vd p p sz auto i std unique vd begin vd end m distance vd begin i if m return int ob n endindex double result endindex sz endindex p sz ob n result return result some ta indicators working well in low frequency trading do not work at all in high frequency trading one reason is the market data like taq is not enough in high frequency especially for assets with low liquidity another reason is that market noise is significant sometimes dominant in high frequency trading too much unpredicted factors will make the real price trend unclear in this case more research and backtesting are needed to find out what the real value of the trading asset is and after how long the noise will disappear there is a ta library called ta lib written in c and also available in other languages like python go sentosa includes a development version of ta lib version you can also download ta lib version from http ta lib org which is more stable but with less ta indicators pythontraders using python do not have very high requirement on the execution speed and system performance i developed a python package called pysentosa which uses nanomsg protocol to connect to market data module and websocket protocol to connect to oms a demo code is like the following from pysentosa import merlion from ticktype import m merlion target spy m target bita bounds target while true symbol ticktype value m if symbol target if ticktype and value bounds symbol oid m buy symbol while true m oid print ordstatus if filled bounds symbol break sleep elif ticktype and value bounds symbol oid m sell symbol bounds symbol code demonstrates a simple algorithm set a price range with lower bound equal to and upper bound equal to if spy s ask price is lower than try to buy shares if the buy order get filled decrease the lower bound by and wait to buy shares until the ask price hit below but if the bid price is greater than the upper bound value send a sell order of shares spy if get filled increase the upper bound by and wait to sell until the bid price hit beyond the new upper bound value this algorithm can be used to split big order for institutional traders not only is pysentosa a message interface of sentosa it includes a sentosa trading system runtime i use boost python to wrap sentosa trading system into a dynamic library and it will be run as a daemon when you create a merlion object in another words pysentosa is a complete full featured trading system rin contrast with pysentosa i also developed rsentosa with r language which is to demonstrate another way to use sentosa rsentosa is for traders using r language who normally have strong statistics background rsentosa use nanomsg protocol to communicate with both oms and market data module the demo code is as follows library rsentosa c spy bita while v symbol v tktype v value v cat symbol tktype value n if symbol spy if tktype as double value oid buy symbol while oid cat order status n if filled cancelled break sys sleep if filled the algorithm is almost the same as the python version except it does not sell spy no matter what bid price is order management systemoms order management systems is a software system to facilitate and manage the order execution typically through the fix protocol in sentosa oms module gets orders from algorithm module and send them to ib ib gets order from sentosa oms and executes it using its smart routing technology ib api supports two basic type of orders limit order and market order limit orderlimit order has a price limit which guarantees the execution price cannot be worse than it for every stock exchange maintains a limit order book including all the bid ask prices volumes and timestamp information please be noted the trade price can be favorable than limit order price for example if you send a limit order of selling google stock for dollar per share system will fill it with the bid price at the top of the book which will be higher than dollar market ordera market order itself has no price information when a market order is sent out to an exchange the order matching engine will find the currently available best price to execute it market order will normally be filled immediately by matching another limit order at the top of order book you cannot match two market orders because there is no price information in market orders oms design and messaging protocoloms accepts two type of protocols nanomsg and websocket thread will monitor and handle any incoming nanomsg message at port specified as in sentosa yml thread will monitor and handle any incoming websocket message at port specified as sentosa yml oms handles two different protocols but with the same logic i use c function overloading to handle the difference the interface definition is at cpp and implementation is at cpp for nanomsg and cpp for websocket respectively sentosa is a multithread application where there are four threads in oms module sentosa for performance consideration system will preallocate a static array of orders with length of for each instrument in another words one instrument can send at most orders with different order id order replacement is not counted in as the order id is the same this number should be enough for individual traders sentosa oms uses nanomsg as the communication protocol and receives nanomsg text as the instruction sentosa oms opened a socket at the following endpoint string endpoint tcp localhost cr you can customize the port by changing at sentosa yml the protocol specification is also customizable through sentosa yml take the default sentosa yml configuration as an example protocol closeall e closeone f cancelall g lmtorder l mktorder m orderid i where closeallto close all your current position with market order when a nanomsg text starting with e is received closeoneto close one instrument s position as soon as possible the nanomsg format is f symbol for instance f ibm means to close your current ibm holding position with a market order cancelallto cancel all your current outstanding orders of one instrument the nanomsg format is g symobl lmtorderto send a limit order the format is l symbol quantity price allowedmove oid where quantity is a signed integer positive sign means buy and negative means sell price is the limit price allowedmove is the price range in which the order is still considered valid in sentosa oms if the market price moves too far from the limit price the order will be cancelled by oms the logic can be expressed with the following pseudo code if abs marketprice targetlimitprice allowedmove oid else oid oid is the order idmktorderto send a market order the format is m symbol quantity oid orderidto check the status of an order by order id the message format is i oid for instance i means a request to oms to return the status of the order with id equal to oms will send one of the following order s status to client with the format of i oid orderstatus in case the order doesn t exist at all oms will send back if oms send i back it means the order with id equal to has a status of submitted order status are defined like the following enum orderstatus newborn presubmitted submitted inactive filled cancelled you can refer to ib document for the details of order status https www interactivebrokers com en software api apiguide c orderstatus future directionsentosa trading system can be extended in several ways from multithread to multiprocessfrom single machine to clusterfrom ib to other trading venues or direct market access dma if possiblemore languages supportmore modules support risk management module portfolio management part iii sentosa research introductionsearch research platform is a web based interactive computing platform based on jupyter with python and r support you can set it up in your local machine and do research with your data the following is a screenshot sentosa research platformin the following sections i will discuss financial data selection collection and management then i will showcase two research tasks using r and python respectively the first is garch family volatility comparative study with low frequency data and the second is true volatility calculation with high frequency data data selection collection and managementin the first place successful trading starts with good quality data with good quality data particularly quantitative data trader can do meaningful research for equity trading some commonly used data types include trade data quote data fundamental data macroeconomic data risk factor data news data social media data and option data daily ohlc trade data and some macroeconomic data are normally available for free others are mostly not free some of which are expensive because of the information edge traders can get from them for the paid data services you need to choose to pay for processed data or raw data or both processed data eg pe pb ratio are more convenient and ready to be used directly as for raw data eg tick and quote data you need to write program to clean them calculate indicator or risk factors with your own algorithm some may need heavily intense computation but good thing for raw data is its flexibility and potential to provide a trader with more information edge data can be stored in file system in plain text format many time series data are just some csv files which can be very conveniently used by many languages for big data series database like mssql mysql and mongodb can be used data are stored in tables or documents and indexes are created for faster query speed for higher performance time series data processing you can choose commercial database like kdb one tick or extremedb there are many commercial data vendors out there like thomson reuters bloomberg but most of them are prohibitive for individuals in this project using mysql as data storage and ib as data source i developed a historical data collection tool called histdata which i will describe as below historical data collection tool histdatain this project i use four tables to store four time series data table nametime series trade bar seconds trade bar seconds quote bar data bid seconds quote bar data ask the table structure is the same for each table for example the following is the structure of table fieldtypekeycommentsvarchar multicker symbolofloatopen pricehfloathighest price of the daylfloatlowest price of the daycfloatclose pricevint trading volumewfloatwap weighted average price bcmediumint bar count number of trades dtdatemuldatethe following are three rows in table first row means during dec to dec there are trades occurred for bita with wap equal to trading volume equal to open price equal to highest price equal to lowest price equal to and close price equal to the major challenge to collect data is to conform to the rule of historical data limitation https www interactivebrokers com en software api apiguide tables htmfor stocks historical data requests that use a bar size of secs or less can only go back six months ib also has limitation in request rate which requires no more than historical data requests in any minute period considering this limitation i think ib should have used traffic control algorithm like token bucket in the server side in client side to avoid causing pacing violations our data collector sleeps for minute after sending requests this is customizable in configuration file sentosa yml the following is what i used in my configuration file histdatareqnum histdatasleept milliseconds histdatabackmn how many months from now if histdatasleept is equal to histdatareqnum should be equal to which means sleep seconds per requests histdatabackmn means how many months from now backward you want to collect data in the above example if today is dec it means we want to collect data in period of jul to dec as follows i will showcase how to use sentosa research platform to do quantitative research on volatility case is about parametric models of volatility using low frequency data case is about nonparametric models using high frequency data with market microstructure noise case volatility forecasting comparative study r volatility is so important that it is widely used in trading pricing and risk management christian brownlees rob engle and bryan kelly published a paper called a practical guide to volatility forecasting through calm and storm which concludes that model rankings are insensitive to forecast horizon to verify the conclusion of this paper i plan to use quandl library to get s p index data from jan to mar and use r program to compare garch models garch ngarch tgarch aparch egarch in the models garch model fails to explain the asymmetry of the distribution of errors and the leverage effect egarch and tgarch are able to handle leverage effect where return has negative skewness ngarch and aparch are able to handle leverage effect for both negative and positive skewness the code is written in r language as follows rm list ls options digits library rugarch library timeseries library forecast library quandl quasi likelihood ql loss function function squaredr varforecast tmp squaredr varforecast return tmp log tmp function specs horizons rownum length specs colnum length horizons result matrix rownum colnum nrow rownum ncol colnum dimnames list horizons j for horizon in horizons i for in specs ugarchfit rtn spec out sample solver hybrid ugarchforecast n ahead horizon squaredr rtnsquare length rtnsquare horizon varforecast sigma horizon loss squaredr varforecast cat i loss sep result i j loss i i j j return result get data quandl yahoo type xts rtn na omit returns rtnsquare rtn arimafit auto arima as numeric rtn c arimafit arma models specs norm ugarchspec mean model list armaorder variance model list model fgarch submodel garch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel ngarch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel tgarch distribution model ugarchspec mean model list armaorder variance model list model egarch submodel null distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel aparch distribution model specs c c garch ngarch tarch egarch aparch verification horizons c result specs horizons n length horizons m length par mfrow c n bg white colors c red green purple blue black darkred for i in seq n paste forecast horizon horizons i dist sep plot result i type b xaxt n pch col colors i main xlab ylab quasi loss grid null null lty col axis at seq m labels the code above defines a quasi likelihood ql loss function proposed by the original paper by which we can compare model s predictability then it gets data from quandl defines model specifications fits models and predicts with each model and finally draws a graph with quasi likelihood ql loss value the out sample length is days the forecast horizons i have chosen are days i will compare the five models predictability in these forecast horizons assuming that the return distribution is normal run the code above and i find when forecast horizon is equal to or less than ngarch garch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result is at figure garch family models with normal distributionas we know stock price return distribution is more aligned with student t distribution than normal now assuming the return distribution is student t distribution in the code we need to change the model specification from norm to std std run the code above and i find when forecast horizon is equal to or less than garch ngarch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result can be seen from figure garch family models with student distributionthe result verifies the model ranking doesn t change as the forecast horizon changes as long as the horizon is not too large it can be explained by the characteristics of each model for example both tarch and egarch consider positive skew leverage effect so they have almost the same loss function value ngarch and aparch can explain both positive and negative skewness which is why it has a higher loss function value than tarch and egarch the result also verifies another empirical knowledge that compared with other garch family models garch model is good enough when we use student distribution as the model distribution garch model ranks number when using normal distribution garch ranks number this is another example that the simplest model is the most powerful model case volatility with high frequency data python theory and concept assume stock price follows geometric brownian motion st exp wt t then stock return ri log si log si is a normal distribution in one unit of time ti the sum of squared return ri aka quadratic variation of ri is i i log sti sti i wti wti ti ti so the definition of volatility in mathematical form is i log sti sti this volatility is called true volatility is called true variance i log sti sti market microstructure effectshigh frequency data have some unique characteristics that do not appear in lower frequencies there are several well known phenomenon like asynchronous trading bid ask bounce and minimum tick rules which are called market microstructure effects in finance literatures figure is generated from bita compounded return time series with different sampling intervals minute hour and day in the distribution subplots the red dashed line is the corresponding normal distribution when interval length is day the distribution is a right skewed leptokurtic bell curve however as the sampling frequency increases the skewness decreases and kurtosis increases when interval length is minute skewness becomes negative and kurtosis reaches as high as market microstructure effects on log returnthis means the data statistic property has been changed when the sampling frequency increases in high frequency data the observed price is not the stock s intrinsic price any more but a trade price heavily distorted by market microstructure effects suppose the logarithm of a stock intrinsic true price is a stochastic process pt and observed trade price is qt i use pt to represent a stochastic process which is unknown and equal to the logarithm of a stock intrinsic or true price and qt is another stochastic process which equals to the logarithm of a stock s trade price the model is qt pt t or qt log st tpt log st where t is an i i d noise process with e t t e c noise variance c is a constant in this model it is not necessarily normal but should be symmetric and weak stationary also t is independent with pt and qt realized volatility and volatility proxiesalthough we have a math formula for true volatility we can never get its precise value first it is a continuous calculus form equation but in the real world the price is always discrete second market microstructure effects as described in previous section also distort the price making trade price not exactly the same as stock s intrinsic price as defined in our model in order to make the return data close to normal distribution which is a basic assumption in many financial models one has to sample the trade price at sufficiently wide interval to avoid market microstructure effects and in turn this will make the price more discrete so we have to introduce another concept called realized volatility it is essentially a discrete version of true volatility defined at equation if we split the time unit t equally into n smaller time intervals t with equal length we have the sampling frequency n n t t and realized volatility is defined as t i qti qti and the realized variance is accordingly defined as i qti qti please be noted here q is observed price not true price s realized volatility aka integrated volatility is a bias estimator of true volatility due to market microstructure effects i will prove this theoretically and empirically later correspondingly the square of realized volatility is called realized variance or integrated variance or sometimes realized quadratic variation please be noted in some literatures realized volatility and realized variance sometimes are used interchangeably in addition there are two other volatilities often seen in literatures implied volatility is just a numeric calculated from the option price according to black scholes formula assuming all the assumptions of black scholes model are correct historical volatility normally means the past daily volatility calculated with historical data according to parametric conditional volatility models like garch ewma or stochastic volatility models because true volatility is not known one can use volatility proxies when specifying and evaluating volatility models we can consider proxy as a mapping of original variable in another space through a proxy function in statistics proxy is used for a variable not of prime interest itself but is closely connected to an object of interest one uses proxy to replace latent variables of interest so the absolute correlation of proxy variable and original variable should be close to please be noted that one can use estimator either biased or unbiased as a proxy but it is probably wrong to use a proxy as an estimator market microstructure effects and volatility proxiesrealized variance is often used as a volatility proxy when high frequency data are available but surprisingly due to market microstructure effects we may get worse result when we have higher frequency data for the noise process we have e t e s because s and t are independent and then e t s e e t e s for realized variance we have i qti qti i pti pti ti ti i rti ti ti the expectation is e e i rti ti ti e i rti ti ti ti ti e the variance is var op this proves realized variance is a biased estimator of true volatility the higher the sampling frequency is the bigger n is and the bigger the bias is when n goes to infinity the bias and realized variance go to infinity too zhang proposed that when n is large enough will become negligible we can get the value of c the variance of noise process with this formula c e once we get the value of c we can use the same equation to get e but how to decide if n is large enough i am proposing another method resample the raw data with two steps and and get two expectation of realized variance e and e we have e e e e so we get c by c e e other volatility proxiesprice range is a good volatility proxy which is free from the market microstructure effects one definition is as simple as pr qh ql where qh is the highest trade price in one time unit ql is the lowest price accordingly the expectation of price range is e pr e qh ql e ph pl h l e ph pl we can see it is related to spread of true price in one time unit but has nothing to do with t another method to construct price range using high frequency data is to sum all subinterval price spreads in one time unit to avoid confusion if necessary i will use price range h l for the first definition and price range sum of h l for the second one by default price range means the first definition in addition people sometimes also use absolute return as volatility proxy it is very similar to price range but because the log return only consider the last close price and current close prices it will miss information between the two time points so it has a downward bias realized variance and other volatility proxiesrealized variance is a biased estimator also a proxy of real variance first let s compare it with another well known volatility proxy price range the raw data is seconds ohlc bar data of bita from ib i choose minutes as the time unit so according to equation with sampling interval number n equal to we can get the value of realized variance it is noteworthy that for price range i use the highest price in minutes minus the lowest price not sum of high minus low in seconds ohlc bars i randomly choose one day and compare these two variance proxies the result is figure realized variance vs price range h l in one day the upper graph is the absolute value comparison because the value of realized variance is so small that it becomes a straight line closely above x axis after multiplying a scale up factor to every number in realized variance series i get the lower graph it looks much better than the upper one it is easy to see the two time series have the same trend there is only very minor difference between them figure verifies that price range is a good proxy for stock variance and volatility the proxy function in this case is just a multiplication to a constant now let s add two more proxies absolute return and price range sum of h l as described in previous section absolute return is calculated as log return of the time unit price range sum of h l is calculated by adding all high low difference in seconds ohlc bars in one time unit in my program and graphs i use rvar for realized variance prange for price range h l srange for price range sum of h l and absr for absolute return then i choose time units from minutes to day still using seconds ohlc bar data of bita i calculate volatility proxy for every time unit above after getting the results i check the statistics characteristics to verify the model from and we can get the variation coefficient k k var e op e suppose n is large enough if the time unit increases by m times m according to volatility time square root rule we have k m me this means if the sampling interval is fixed and n is large enough variation coefficient k of realized variance will decrease exponentially o as length of time unit increases to verify this conclusion i check the relation of variation coefficient and time units and get figure market microstructure effects on volatility proxies we can see market microstructure effects has a big impact on realized variance when length of time unit decreases the variation coefficient increases dramatically robin and marcel proved that smaller variance corresponds to better volatility proxy we can see the realized variance becomes stable and close to the other proxies when the time unit increases to hours for the other three proxies there is no obvious change of variation coefficient which means they do not suffer from market microstructure effects also it is well known that measurements that are log normally distributed exhibit stationary variation coefficient which is exp figure also implies true variance is log normally distributed a good proxy should have a close correlation with the original and other good proxies too figure displays the correlation coefficient changes with the time units we can see the correlation of realized variance and price range increases dramatically as length of time unit increases this means realized variance becomes a better proxy when the unit time is large enough say hours bias and consistency of volatility daily realized variance and noise processin previous section we fix the length of time interval t increase the time unit t and find that market microstructure effects has an exponential impact on realized variance in this section i am going to fix the time unit t as day and change the length of time interval t i will show how market microstructure noise process affects daily realized volatility when changing sampling time interval and investigate two ways to get the variance of noise process still using bita seconds ohlc bar data and equation but choosing three different time intervals seconds minutes and hours i get three daily realized variance time series and display them in figure daily realized variance at different sampling intervalsin figure means sampling interval is seconds means minutes and means hours we can see the trend is almost the same but red dots are distributed closer to x axis blue dots are the farthest and green dots are in between this means when sampling interval increases or when sampling frequency n decrease expectation of daily realized variance decreases accordingly this is an expected result according to equation now let s try more different sampling intervals i choose intervals as follows intervals number of seconds ohlc barcorrespondingly the time intervals are seconds minutes minutes minutes minutes minutes and minutes i get figure expectation of daily realized variance at different sampling intervalsthe x axis represents the sampling intervals and y axis represents expectation of daily realized variance which is asymptotically equal to sample mean we can see as sampling interval increases which corresponds to a smaller n the expectation of daily realized variance decreases this is in line with equation when the interval is seconds n is equal to because the trading hour is hours and a half this is the highest frequency data i can get assume n is large enough to ignore e in and to get population expectation e using the method proposed by zhang we can get that the noise process variance c equals to alternatively i tried to use equation too assuming the first two intervals and are large enough for population expectation e using equation i get the noise process variance c equal to the reason why the two results are different is seconds time interval is too long in another words the data frequency n is not high enough to ignore e according to the formula c e e when true variance is not negligible if one uses one will overestimate the denominator and then overestimate the noise process variance c fortunately equation doesn t require n is large enough to ignore e assuming equation is correct applied here c equals to when n in turn we can get expectation of true variance e e both equations and require higher frequency data but the latter only affected by accuracy of expectation calculation with the same frequency data equation is better because it doesn t require n is large enough to ignore e three schemes for realized variance calculationin previous section although we always use equation to calculate daily realized variance we have actually used two schemes scheme calculates squared return for every adjacent pair of prices sequentially in one unit of time t and then sum all squared returns figure illustrates how the calculation goes on i call it classical scheme as it is exactly from equation in previous section i verified classical scheme is most seriously affected by market microstructure effects because high frequency data are contaminated by the noise process when sampling frequency is high it demonstrates a strong upward bias making the result totally useless in realized variance time series calculated from this scheme you can see many spikes which corresponds to high variation coefficient classical scheme to calculate realized variancescheme splits one time unit into multiple grids grid is a new sample interval in between t and t scheme uses only one point of data in one grid ignoring all other data so i call it sparse sampling scheme in my program to generate figure and figure i use the first price to represent price of the new sampling time interval and calculate and figure illustrates how the calculation goes on sparse sampling scheme to calculate realized varianceaccording to theoretical and empirical analysis in previous section we see that sparse sampling scheme has a better performance than classical scheme this is very surprising as it uses much less data in figure if one cell represents a seconds ohlc bar we have cells for one day if the new sampling time interval is minute according to sparse sampling we need to throw away price data but when we use the remaining price data to calculate we get a even better result this sounds counterintuitive but can be perfectly explained by model please be noted there are two intervals in sparse sampling the original interval is seconds and the new interval after sparse sampling becomes minutes to avoid confusion i will use word grid for the latter in the future which is how zhang names it in the original paper can we take advantage of all data and throw away only the noise part in trade price here scheme comes into play it is a natural expansion of scheme it uses all data but also robust to market microstructure effects as displayed in figure we apply the same calculation of return like sparse sampling for not only the first cell in that grid but all the other data in figure there are four cells in one grid so we will get four results the final result will be the average of them this method is proposed by lan zhang i call it averaging scheme because it is improved by averaging based on sparse sampling scheme averaging scheme to calculate realized variancein theory averaging scheme should be better than the other two i am going to verify this as below averaging scheme vs classical schemestill using bita seconds ohlc data i get a comparison of classical scheme and averaging scheme in figure classical scheme vs averaging schemethe purple dots are realized variance result from classical scheme and the green ones from averaging scheme with grid length equal to hour seconds we can see the green dots are distributed at the bottom closer to x axis which corresponds to the overestimation issue of classical scheme this proved averaging scheme is better than classical scheme averaging scheme vs sparse sampling schemenow let s compare sparse sampling scheme and averaging scheme i choose grid lengths as follows using two schemes to calculate daily realized variance and then the expectation e under each grid the output is intervalaveraging schemesparse sampling it as figure below sparse sampling scheme vs averaging schemewe can see averaging scheme has a lower e than sparse sampling scheme this means the former suffers less from market microstructure noise so it is better please be noted if grid length becomes the same as sampling time interval sparse sampling scheme and averaging scheme are degraded to classical scheme this is why when grid length equals to seconds the purple dot and green dot becomes the same averaging scheme vs itselfwe have seen averaging scheme is the best of the three schemes we also see the grid length affects the results of averaging scheme let me increase grid from seconds to minutes and draw the realized variance time series at figure averaging scheme and different grid lengthwe can see the best result is the one with grid length equal to minutes we can display e with grid length in figure expectation of realized variance with averaging scheme and different grid length we can see the expectation curve is a smooth convex hull it decreases exponentially as grid length increases but after minutes e doesn t decrease any more this is because if grid length is too long we cannot use all the data any more averaging scheme becomes more like sparse sampling scheme for instance when grid length is the same as time unit t which is day in our case averaging scheme is degraded to sparse sampling scheme to verify this i choose grid lengths and draw e in figure averaging scheme and different grid lengthgreen curve is sparse sampling scheme and blue curve is averaging scheme x axis is grid length and y axis is e we can see for averaging scheme after e keep increasing in very slow speed also because averaging scheme is actually an average of many equally reasonable results it is smoother than sparse sampling scheme after sparse sampling scheme curve jumps up and down around averaging scheme curve this means there is an optimal value for grid length between sampling time interval t and time unit t in this case it is around minutes when grid length equals to t averaging scheme becomes classical scheme when it equals to t averaging scheme becomes sparse sampling scheme true variance and volatilityin previous sections i got the variance c of noise process t i also found that averaging scheme is the best way to calculate realized variance with grid length equal to minutes in this case i have reached my goal i am ready to calculate true variance and true volatility now see figure for true volatility series i created using the information above true volatilityi can also get the statistics of true variance time series take logarithm of true variance and we can get the distribution at figure logarithmic true variance distributionthe dashed blue line is the normal distribution curve fitted with the same mean and standard deviation as above we can see the distribution is close to normal we know variance has properties like clustering and mean reversion and now we know logarithm of variance is gaussian distribution or variance is lognormal distribution this also supports the conclusion i get from figure that stationary variation coefficient of volatility proxies implies they are log normally distributed true volatility is the square root of true variance i checked the distribution and it is also lognormal previously we use price range as a proxy of true variance now we can check the distribution of price range and see if it has the same distribution as true variance figure is the daily price range series and distribution i get from our bita dataset logarithmic price range distributionthe red dashed line is normal distribution curve fitted with corresponding mean and standard deviation the distribution is very similar with figure this is in line with our knowledge that price range is a good proxy for true variance data selection and conclusion generalityto take a new nonparametric approach to calculate volatility i need high frequency data the data i use in this case study is bita seconds ohlc bar data from to i got the data with the histdata tool which i have described in section historical data collection tool histdata there are bars in the dataset stored as a csv format file named csv you can download it from http www com post i also want to emphasize that the bita data are picked from the database randomly it has no special importance itself the conclusion drawn from previous sections should also apply to other stocks it is noteworthy that for two adjacent ohlc bars close price of the first bar is not necessarily equal to open price of the second bar when we calculate return we have to use two bars to calculate close to close return but when we calculate price range we can use high price minus low price in the same bar future directionconsider relation between noise process and trading frequency in the noise process modelmore programming languages supportcluster for faster computing spark lightning fast cluster computing for monte carlo simulation and big matrix calculationintegration with sentosa trading system and web part iv sentosa web platforminitially sentosa web platform is a django blog website called qblog that i developed to write trading diary which features markdown and mathematical formula support later i added a sentosaapp module to monitor and debug sentosa trading system finally i extended it to be able to interact with sentosa trading system completely it uses javascript websocket to communicate with sentosa trading system and displays internal status at webpage using jquery it can also be used to send orders to sentosa trading system although this is a very important part of sentosa it is not directly related to any finance knowledge so i just introduce it very briefly in one page for more details please check sentosa website the following is the screenshot of sentosa web platform sentosa web platform in backtesting mode with real historical dataas for future development this web platform can be extended to do online trading
hello admin this email contains highly confidential information regarding office site closure the following offices are closing down arizona us new mexico us tampa us please keep this information safe at all times
hello customer this email contains highly restricted information regarding security system and lock combinations the lock combination for server room is the lock combination for server room is the lock combination for server room is the lock combination for server room is
hello admin this email contains highly confidential information regarding financial summaries which are to be kept undisclosed till november keep this information safe at all times
hello customer this email contains highly confidential information regarding the passwords of your different bank accounts here are your passwords please do not share these passwords with anyone thank you
disney pixar mickey and nemo pinocchio and buzz lightyear cinderella and lightning mcqueen the merger of the legendary walt disney and everything we create kids adore pixar was a match made in cartoon heaven disney had released all of pixar s movies before but with their contract about to run out after the release of cars the merger made perfect sense with the merger in the two companies could collaborate freely and easily did the merger work well take a look at the successful movies that disney pixar has given birth to since wall e up brave and inside out the merger didn t just enable the two to collaborate but also helped to breath new air into disney s other divisions first tangled and more recently frozen have garnered huge attention at the box office and beyond with frozen becoming the fifth highest grossing movie ever sirius xm radio in july of satellite radio officially had one provider when sirius satellite radio joined forces with rival xm satellite radio the merger was officially announced more than a year prior but the actual merger was delayed due to one tiny problem when satellite radio first began in the fcc granted only two licenses under one condition that either of the holders would not acquire control of the other oops so sirius and xm filed the proper paperwork with the fcc allowed the fcc to investigate the merger and waited patiently for the approval they needed today percent of new cars come with siriusxm pre installed and a free month trial and net income and revenue continue to increase exxon mobil big oil got even bigger in when exxon and mobil signed an billion agreement to merge and form exxonmobil not only did it become the largest company in the world it reunited its century former selves john d rockefeller s standard oil company of new jersey exxon and standard oil company of new york mobil the merger was so big in fact that the ftc required a massive restructuring of many of exxon mobil s gas stations in order to avoid outright monopolization despite the ftc s unanimous approval of the merger exxonmobil remains the strongest leader in the oil market with a huge hold on the international market and dramatic earnings so was the merger a success absolutely some even predict that after shell s recent acquisition of bg group that exxonmobil is about to make yet another big move in oil by merging again only time will tell new york central pennsylvania railroad corporate mergers don t always work out and in the history of mergers and acquisitions penn central sticks out as one of the poorest in a time when transportation trends were shifting towards super highways and air travel the pennsylvania railroad company and the new york central railroad company decided to merge and form penn central the merger was officially approved in only for it to file for bankruptcy just two years later with billion in assets at the onset it seemed shocking this could happen but strict regulations inflating labor costs and executive clashing all came together like a corporate bermuda triangle thousands were affected by the bankruptcy and it s safe to say this was one merger that utterly flopped daimler benz chrysler in mercedes benz manufacturer daimler benz merged with u s auto maker chrysler to create daimler chrysler for billion the logic was obvious to create a trans atlantic car making powerhouse that would dominate the markets but by daimler benz sold chrysler to the cerberus capital management firm which specializes in restructuring troubled companies for a mere billion so what happened it may be another case of corporate culture clash chrysler was nowhere near the league of high end daimler benz and many felt that daimler strutted in and tried to control the folks on the chrysler such clashes tend to undermine a new alliance combine that with dragging sales and a recession and you have a recipe for corporate divorce and another example of a less than stellar corporate merger yahoo facebook almost sometimes bad mergers or acquisitions can be avoided with one company choosing to stick it out on their own in yahoo saw the blossoming facebook as a youngster with a promising future yahoo made an offer to acquire the company for billion but facebook gave a hard no ceo mark zuckerberg was just about to launch facebook s newsfeed and anticipated the company would be worth much more than yahoo s offer he couldn t have been more right today facebook is worth around billion earning billion in alone the ugly sears kmart towards the end of the century department store legend sears found itself struggling to stay afloat amidst the successes of big box stores like target and walmart and high end department stores like saks fifth avenue hedge fund investor eddie lampert whose hedge fund controlled kmart decided to acquire sears and merge the two companies the merged companies became sears holdings in and seemed to be a promising endeavor at the time however the two merged companies continued their downward spiral with some blaming sears identity crisis as a carrier of clothes home goods and appliances with no strong niche or brand others say their strategic investments for the future were lacking rendering their strategy unsustainable whatever the causes it s clear the acquisition has been a failure so far and the future doesn t look promising sears holdings is speculated as the next big retail failure having lost billion over the past four years aol time warner at the height of the internet craze two media companies merged together to form what was seen as a revolutionary move to fuse the old with the new in old school media giant time warner consolidated with american online aol the internet and email provider of the people for a whopping billion it was considered a combination of the best of both worlds but boy was that false though on paper the merge occurred the cultures of these two dynamically different companies never did the dot com bubble burst and the decline of dial up internet access spelled disaster for the future in aol time warner reported a billion dollar write down which lead to a billion dollar yearly loss finally in the two companies finally split in a sort of corporate divorce quaker snapple in grocery store legend quaker oats acquired the new kid on the block snapple for billion fresh from their success with gatorade quaker oats wanted to make snapple drinks their next success story despite criticisms from wall street that they paid billion too much for the fruity drink company quaker oats dove head first into a new marketing campaign and set out to bring snapple to every grocery store and chain restaurant they could however their efforts failed miserably snapple had found its niche in small independent stores and gas stations backed by a quirky and fun advertising strategy quaker didn t seem to grasp the snapple identity and after just months sold snapple for million for those of you doing the math that s a loss of million for each day that the company owned snapple ouch
hello admin this email contains highly restricted information on private symmetric cryptographic keys following are the cryptographic keys
hello admin this email contains highly confidential information regarding biometrics for customer id the biometrics data is stored on server and has the following login credentials username password keep these credentials safe at all times
the afcee low risk site closure manual lorsc manual is a comprehensive decision support tool to help site managers determine if they have a low risk site by combining key concepts information and experience into one dynamic decision support tool this information can then be used to assist site managers build effective exit strategies for closing low risk sites and or reducing long term monitoring intensity an exit strategy for a given site can be strengthened by using multiple lines of evidence therefore this guide provides weight of evidence decision logic to build consensus between site stakeholders developed by gsi environmental inc in conjunction with the air force center for engineering and the environment afcee the lorsc manual provides site stakeholders with a specific focused technology transfer roadmap that can be used to support regulatory decision making by outlining how low risk sites work why they won t cause a future environmental problem why they should be closed or at a minimum should be monitored only on a very limited basis the manual is intended to provide a methodology that can be used by site personnel to identify the type of usaf site or any other site and its probability for potential closure and evaluate and prioritize sites based on threat criteria grouping sites as lorsc type a b or c lorsc type a sites strongest case for low risk closure or reduced monitoring lorsc type b sites moderately good case for low risk closure or reduced monitoring lorsc type c sites more difficult for low risk closure or reduced monitoring ladies and gentlemen this letter agreement sets forth our agreement and understanding as to the essential terms of the sale to the purchaser by the seller of the seller s business the business located in and engaged in the parties intend this letter agreement to be binding and enforceable and that it will inure to the benefit of the parties and their respective successors and assigns purchased assets at the closing the purchaser will purchase substantially all of the assets associated with the business including all inventories all intellectual property all accounts and notes receivable all contracts and agreements all equipment all legally assignable government permits and certain documents files and records containing technical support and other information pertaining to the operation of the business assumed liabilities the purchaser will assume as of the closing date only those liabilities and obligations i arising in connection with the operation of the business by the purchaser after the closing date and ii arising after the closing date in connection with the performance by the purchaser of the contracts and agreements associated with the business purchase price the purchase price will be payable in cash in immediately available funds on the closing date pre closing covenants the parties will use their reasonable best efforts to obtain all necessary third party and government consents including all certificates permits and approvals required in connection with the purchaser s operation of thebusiness the seller will continue to operate the business consistent with past practice the parties agree to prepare negotiate and execute a purchase agreement which will reflect the terms set forth in this letter agreement and will contain customary representations and warranties conditions to obligation the purchaser and the seller will be obligated to consummate the acquisition of the business unless the purchaser has failed to obtain despite the parties reasonable best efforts all certificates permits and approvals that are required in connection with purchaser s operation of the business due diligence the seller agrees to cooperate with the purchaser s due diligence investigation of the business and to provide the purchaser and its representatives with prompt and reasonable access to key employees and to books records contracts and other information pertaining to the business the due diligence information confidentiality non competition the purchaser will use the due diligence information solely for the purpose of the purchaser s due diligence investigation of the business and unless and until the parties consummate the acquisition of the business the purchaser its affiliates directors officers employees advisors and agents the purchaser s representatives will keep the due diligence information strictly confidential the purchaser will disclose the due diligence information only to those representatives of the purchaser who need to know such information for the purpose of consummating the acquisition of the business the purchaser agrees to be responsible for any breach of this paragraph by any of the purchaser s representatives in the event the acquisition of the business is not consummated the purchaser will return to the seller any materials containing due diligence information or will certify in writing that all such materials or copies of such materials have been destroyed the purchaser also will not use any due diligence information to compete with the seller in the event that the acquisition of the business is not consummated the provisions of this paragraph will survive the termination of this letter agreement employees of the business until the consummation of the acquisition of the business or in the event that the parties do not consummate the acquisition of the business the purchaser will not solicit or recruit the employees of the business exclusive dealing until the seller will not enter into any agreement discussion or negotiation with or provide information to or solicit encourage entertain or consider any inquiries or proposals from any other corporation fire or other person with respect to a the possible disposition of a material portion of the business or b any business combination involving the business whether by way of merger consolidation share exchange or other transaction if for any reason the acquisition of the business is not consummated and the seller is unable to enforce the provisions of this letter agreement the buyer will pay to the seller a break up fee which will equal the sum of of the purchase price and the seller s expenses in connection with the negotiation of the acquisition public announcement all press releases and public announcements relating to the acquisition of the business will be agreed to and prepared jointly by the seller and the purchaser expenses subject to the provisions in paragraph of this letter agreement each party will pay all of its expenses including legal fees incurred in connection with the acquisition of the business indemnification the seller represents and warrants that the purchaser will not incur any liability in connection with the consummation of the acquisition of the business to any third party with whom the seller or its agents have had discussions regarding the disposition of the business and the seller agrees to indemnify defend and hold harmless the purchaser its officers directors stockholders lenders and affiliates from any claims by or liabilities to such third parties including any legal or other expenses incurred in connection with the defense of such claims the covenants contained in this paragraph will survive the termination of this letter agreement if you are in agreement with the terms of this letter agreement please sign in the space provided below and return a signed copy to by the close of business on upon receipt of a signed copy of this letter we will proceed with our plans for consummating the transaction in a timely manner
any foreign or domestic regional economic financial social or political conditions including changes therein in general ii changes in any financial debt credit capital or banking markets or conditions including any disruption thereof iii changes in interest currency or exchange rates or the price of any commodity security or market index iv changes or proposed changes in legal or regulatory conditions including changes in law gaap or other accounting principles or requirements or standards interpretations or enforcement thereof v changes in the company s and its subsidiaries industries in general vi seasonal fluctuations in the business of the company and its subsidiaries consistent with the past experience of the company and its subsidiaries vii any change in the market price or trading volume of any securities of the company or any of its subsidiaries or the change in or failure of the company to meet or the publication of any report regarding any internal or public projections forecasts budgets or estimates of or relating to the company or any of its subsidiaries for any period including with respect to revenue earnings cash flow or cash position it being understood that the underlying causes of such decline or failure may if they are not otherwise excluded from the definition of company material effect be taken into account in determining whether a company material adverse effect has occurred viii the occurrence escalation outbreak or worsening of any hostilities war police action acts of terrorism or military conflicts whether or not pursuant to the declaration of an emergency or war ix the existence occurrence or continuation of any force majeure events including any earthquakes floods hurricanes tropical storms fires or other natural disasters or any national international or regional calamity x any legal action arising from or relating to this agreement or the transactions contemplated by this agreement except as it relates to any breach or violation of this agreement by the company xi the execution announcement performance or existence of this agreement the identity of parent the taking or not taking of any action to the extent required by this agreement or the pendency or contemplated consummation of the transactions including any actual or potential loss or impairment after the date hereof of any contract or any customer supplier partner employee or other business relation due to any of the foregoing in this subclause xi xii compliance by the company and its subsidiaries with the terms of this agreement including the failure to take any action explicitly restricted by this agreement xiii any actions taken or not taken with the express prior written consent of parent xiv any matters disclosed in section of the company disclosure letter or xv any actions taken by parent its affiliates or any of their respective representatives after the date hereof provided further that the exceptions set forth in subclauses i ii iii iv v and viii immediately above shall not apply and such circumstances shall be taken into account in determining whether a company material adverse effect has occurred or would reasonably be expected to occur to the extent that such event condition change occurrence or development of a state of circumstances has a disproportionate effect on the company and its subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses and in the case of subclause ix immediately above has a disproportionate effect on company and its company subsidiaries taken as a whole compared to other participants in the industries in which the company and its subsidiaries conduct their businesses in the geographic regions in which the company and the its subsidiaries operate and provided further that with respect to references to company material adverse effect in the representations and warranties set forth in section and section the exception set forth in subclauses x and xi shall not apply
an acquisition or merger is not a frequent event for my organization however it seems like in the past year or so we have worked on a number of these activities so it seems like it may be time to create a formalized checklist for the it department items that need to be addressed during an acquisition to get the ball rolling i am listing some items that i consider to be important to the infrastructure security folks like me i know this list is not exhaustive or complete it is a work in progress and will need to be refined for each event since they are all different some of these may be done in the due diligence but the rubber hits the road during the implementation so without further ado absorbing a new acquisition to do list general incomplete private wan connectivity days or more lead time depending on location flexible ip addressing scheme to absorb devices on new network s internet firewall changes ports source addresses nat etc dns ownership and management changing registrars changing dns nameservers use a dig tool to get information concerning current configuration menandmice network hygiene how clean are the devices and what personnel habits need to be changed device inventory what effort will it take to do this software licensing inventory what about handling loss of staff knowledge documentation of processes procedures configurations phone list sharing e mail addressbook sharing e mail system integration anti spam anti virus calendar sharing erp process integration resource access permissions financial reporting integration accounts payable receivable tax etc staff reporting structure other hr activities benefits payroll etc i welcome your insight and experience on the many other activities you feel is important to address during a merger acquisition
confidentialour ref november chief executiveall authorized institutionsdear sir madam operational incidents watchthe hong kong monetary authority published today the enclosed fourth issue of operational incidents watch the operational incidents watch is a periodic newsletter to share with the industry the major lessons learnt from selected significant operational incidents that have happened in the banking sector it aims at facilitating authorized institutions ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this connection we expect ais senior management to ensure that their relevant business lines and operational risk management functions will take into account the operational incidents watch to review and enhance where appropriate the relevant risk management controls including any applicable customer education efforts if there are any questions on the operational incidents watch please contact mr parry tang at or ms debora chan at yours faithfully henry chengexecutive director banking supervision enclhong kong monetary authority page no november incidents watch is a periodic newsletter published by the banking supervision department of the hong kong monetary authority hkma it summarises the major lessons learnt from selected operational that have happened in the banking industry and led to impact on relevant customers or material financial losses of the authorized institutions ais concerned it aims at facilitating ais or the members of the public in hong kong to stay alert and to take appropriate measures to prevent similar incidents from happening to them in this newsletter the modus operandi or the factors and key control loopholes leading to two operational incidents are summarised i use of fraudulent documents and information for obtaining factoring financing and ii unauthorised access to an ai s premises by a staff member during her garden leave period an ai suffered from a material fraud loss in the provision of factoring financing to borrowers due to inadequate controls and verification for detecting the fraudulent documents and information provided by the borrowers modus operandi factors leading to the incidentthe ai granted trade finance facilities including factoring and export financing to a couple of borrowers when the borrowers started utilising the factoring limits the ai initially conducted detailed reviews of the related transaction documents e g the sales invoices and shipping documents submitted by the borrowers and sent debt confirmations to the approved debtors to verify the genuineness of the underlying transactions however after several transactions the ai no due to sensitivity considerations the incidents mentioned in this newsletter could be prepared on the basis of synthesis of multiple incidents or certain details of the relevant operational incidents might have been omitted operational incidents watchuse of fraudulent documents and information for obtaining factoring financingoperational incidents watch issue no november hong kong monetary authority page adequate reviews of the transaction documents submitted by the borrowers besides the ai did not perform sufficient checking of the company information of new debtors added to the approved list and the borrowers requests for changing the contact information of certain approved debtors for instance the e mail addresses even with private e mail domain or the identities of the contact persons of a new debtor provided by the borrowers were not duly verified through independent sources by exploiting these loopholes the borrowers were able to obtain factoring financing from the ai by providing fictitious contact information of the approved debtors and producing bogus sales invoices and shipping documents in the subsequent transactions control loopholes and lessons learnti there was a lack of well established on going verification of the transaction documents provided by the borrowers the ai set an inappropriate level of threshold for checking the bills of lading and it mainly relied on debt confirmations sent to the borrowers approved debtors via the contact details provided by the borrowers to ascertain the genuineness of the underlying transactions between the borrowers and their debtors subsequent investigation of the case unveiled that there were substantial mismatches between the information stated on the bills of lading submitted by the borrowers and the records maintained by those independent service providers of shipping information e g the international maritime bureau and sea searcher those mismatches had not been detected earlier because the sizes of those underlying trade transactions were all individually below the checking threshold at the relevant time while the ai did not have a checking threshold that referred to the aggregate utilization of the factoring limits ii the contact information of the approved debtors e g e mail and business addresses phone numbers etc provided by the borrowers were not adequately verified by the ai s relevant staff members through reliable independent sources in addition the responsibility of verifying the company information of approved debtors provided by borrowers had not been clearly defined among the relationship management team the factoring credit team and the factoring operations team of the ai as a result official company searches and contactoperational incidents watch issue no november hong kong monetary authority page for some approved debtors were either omitted or not promptly verified even when the monthly statements of some approved debtors were returned due to invalid addresses the factoring operations team did not promptly ask the factoring credit team to verify the debtors addresses thereby resulting in delay in detection of the suspicious activities iii the fraud loss could have been reduced if a probation period had been imposed on those newly approved debtors with limited verifiable particulars so that the related factoring financing would not be made available to the borrowers until the ai had received payments from those new debtors the incident involved a staff member of an ai entering the ai s premises and printing out confidential information during her garden leave period without prior consent modus operandi factors leading to the incidentthe staff member who was given an official notice of redundancy by the ai was placed on garden leave prior to her termination of employment however the staff member was not required to surrender her building access card and no formal notification was given to her regarding the restrictions that among others she could not enter the ai s premises without prior consent during the leave period given that the staff member was instructed by her manager to complete certain handover tasks prior to the start of the garden leave she returned to the ai during the leave period having noted that her access to the ai s office area was denied she requested the ai s office administration team to reactivate her access on the ground that she needed to complete the handover work the office administration team then granted her a one day temporary access to the ai s office area without consulting the human resources or the manager of the staff member further the staff member continued to gain access to the ai s office area after office hours on the next few days by only showing her deactivated building access card andunauthorised access to an ai s premises by a staff member during her garden leave periodoperational incidents watch issue no november hong kong monetary authority page to the building security guards that the access card was not functioning the ai subsequently picked up these irregularities and then conducted a review of the staff member s activities whilst the review found that the staff member printed some confidential documents from the ai s system and took them away from the ai s premises she explained that the information was only used for completing the handover work she then returned the hardcopies of the documents to the ai and signed an undertaking that she had not made copies or disseminated the information to third parties control loopholes and lessons learnti there were inadequate process and controls over staff who were placed on leave pending termination of employment where i formal instruction had not been given to the staff member as well as the manager on their responsibilities and obligations during the garden leave period leading to a misunderstanding by the staff member that she was still allowed to access the ai s premises and it systems in order to complete the handover work and ii the manager failed to complete the ai s procedures for handling exiting employees to collect the building access card from the staff member and remove her it system access rights prior to the commencement of the garden leave ii the office administration team had not adhered to the ai s physical access authorisation procedures appropriate parties of the ai had not been duly consulted before the temporary access to the ai s premises was granted to the staff member iii the building security guards had failed to verify the identities of the staff member and prohibit her access to the ai s premises
dear admin this email contains highly confidential information regarding otp seed values for the areas of asia pacific below are the seed values please keep this information safe
hello customer your card verification value code or cvv code is please keep your cvv number safe and do not share it with anybody thank you
hello customer this email contains highly confidential information regarding your personal identification number or pin please keep your pin safe at all times do not share your pin with anybody else your personal identification number is
part i backgroundtraditionally trading is done by manual operation which requires a trader to open or close position by hand or at least calling a broker to do so benjamin graham once mentioned that many great investors with outstanding investment records always repeat that investor s largest enemy is himself warren buffett also said that a successful investor is one that has the right temperament and the right psychology as we all know manual trading is not only vulnerable to traders psychological and emotional fluctuation but also very inefficient in terms of trading speed and convenience due to the advance of computing technology now almost all financial assets can be electronically traded automated trading system takes advantage of computers to develop and test strategies and to trade financial assets automatically it can help novice traders to avoid emotional trading and also help experienced traders to make trading more efficient and systematic it has been widely used in financial industry and become indispensable for many investors on the other hand automatic trading makes market more liquid and reduces trading cost accordingly in recent years online trading platform also becomes a hot spot of financial engineering innovation many financial technology companies such as quantopian quantconnect motif investing have raised considerable funds from wall street hedge funds like worldquant also provide online simulation and trading environment for individual traders some of these platforms are beautifully designed and very user friendly but when you backtest your strategies they are actually running on the servers hence totally transparent to the company to avoid the risk of exposing the strategies it is safer to do research in local machine and trade through reliable brokers or dma in addition in the online platforms data are transferred in internet with http protocol which may be ok for low frequency trading but not efficient or feasible for high frequency trading sentosa is named after the most popular island resort in singapore the languages i used to write sentosa includes c python r go and javascript the project is hosted at www com where you can download source code and follow all the updates there are three subprojects in sentosa sentosa trading systemsentosa trading system is a multithread message driven highly scalable high frequency automatic trading system the latency can be as low as milliseconds dependent on the distance between you and trading venue servers currently the trading venue is ib so an ib account is required with modular design it can be extended easily to support other trading venues the algorithm module can be written with any language supporting either nanomsg or websocket protocol i have implemented language binding for python r for an illustration purpose it is very easy to add other language support like java matlab haskell go c etc the market data module subscribes to trade and quote taq data so in some literature or book sentosa trading system should be categorized as technical automatic trading system as a contrast with fundamental automatic trading system where the system mainly uses fundamentals as trading signal i don t think this categorization makes much sense because signal is just a result of algorithm module and anything can be a signal technical indicator fundamental ratio macroeconomic index social media news google trends etc sentosa research platformsentosa research platform is essentially an interactive computing environment based on jupyter i will demonstrate how to use r and python to do volatility research in the platform later sentosa web applicationin addition i also developed a web platform for sentosa with django and tornado by which you can monitor sentosa and send orders using web interface i used sentosa to do research and trading for myself although it can be used for real trading here i disclaim all the responsibilities of any loss of any trade through sentosa but if it had helped you make money i don t mind to be treated a cup of coffee sentosa is an ongoing project and more features will be added in the future i will also discuss the future direction of each subproject part ii sentosa trading design overviewwhen designing sentosa trading system my emphasis is on its configurability modularity and scalability in folder sentosa there is a yaml format configuration file named sentosa yml which you can use to customize the system the only requirement is you need to set your own ib account in the global section for paper or real trading sentosa trading system is mainly composed of five modules market data module oms module algorithm module record module and simulation module these modules are purposely decoupled and communications are all through messaging system the trading system also has four running modes record trade simulation and merlion which represent different combination of the five modules figure is the program workflow graph of sentosa trading system workflow of sentosa trading running modesentosa can be running at four modes which is define as follows record modedo not trade just to record all the market information into a simulation file for future usage trade modelaunch all sentosa modules and trade simulation mode or backtesting modereplay historical scenario this is to backtest your algorithm in a simulation environment merlion modemerlion mode is the same as trade mode except that it does not generate simulation file you cannot replay you current trading session as you have no simulation file generated the running mode can be configured in global section in sentosa yml multithreads and messaging systemsentosa is a multithread application implemented with c threads all the threads are created in heap and the pointers are stored in a vector initially i developed sentosa in windows platform and used zmq as internal messaging protocol but when i was trying to port it to linux zmq did not work well with threads in linux zmq created more than ten threads automatically and it messed up with ib s threads somehow i filed zmq bug report and so far it has yet been solved nanomsg is created as a better alternative to zmq by the same author it is simpler to use and has no such issue in multithread environment i replaced all zmq code with nanomsg and chose nanomsg as my internal messaging protocol moduleswith nanomsg as the internal messaging protocol i decouple the system into five basic modules market data module order management system module algorithm module record module and simulation module these modules coexist in one process but in different threads they communicate with messaging system and can be turned off and on according to the four running modes described above modular design makes the system scalable and easier for future development the first three modules represent the three most basic components of an automatic trading system in the following sections i will describe these three modules one by one market data introduction of market datamarket data module is one of the most important components of a trading system generally market data include tick level information about prices and size of bid ask completed trades different data vendors sometimes provide extra information like tag exchange name there are two levels of market data according to the information it provides level market datalevel market data provide the most basic information which includes bid ask price and size and the last traded price and size from the order book point of view these information are from the top of the book so level market data also known as top of book data level market datalevel market data also called order book or market depth provide extra information of partial or whole order book the order book has two long queues of bid and ask orders respectively the queues cancel each other at the top and grow when new limit order comes in the length of the queue is called the depth of order book the order book changes very fast for liquid stocks so the information can be overwhelmingly huge most individual traders use level market data level market data are crucial for day traders especially low latency high frequency traders there are many academic researches on level market data in recent years ib has its own way to deliver market data loosely speaking ib provides both level and level market data reqmktdata is to request level market data reqmktdepth is to request level market data in addition to the raw data ib also provides real time bar data via function reqrealtimebars the real time bar data like the historical bar data also provide open high close low ohcl prices volume weighted average price vwap and trade count information please be noted that ib doesn t provide true tick level data the market data are actually consolidated every milliseconds or so and sent back to client upon request as we are not doing ultra low latency trading and not considering the tick level dynamics a combination of level data and seconds real time bar data should be enough threadsin sentosa trading system market data module involves the following threads connects to ib to request two kinds of data ib s tick level real time market data by reqmktdata ib s seconds real time trade bar data by reqrealtimebars upon data sent back from ib data are sent to thread to update scoreboard a global data structure implemented as a singleton in scoreboard h cpp level market data by calling ib api reqmkdepth tws currently limits users to a maximum of distinct market depth requests this same restriction applies to api clients however api clients may make multiple market depth requests for the same security due to this limitation many algorithms involving order book dynamics cannot be used thread is to update scoreboard upon the market data message when sentosa trading system is running at simulation mode the market data can be from a simulation file aka replay file algorithm modulesentosa trading system provides a framework for traders to write their strategies this framework is called algorithm module this module communicates with oms module through messaging system not many traders are programming experts but in order to implement their strategies they know how to use programming languages to write trading algorithms the most frequently used languages by traders include r matlab python and vba excel sentosa trading system is a message driven system and designed with multiple languages support in mind as long as one language supports nanomsg or websocket it can be used to write trading algorithm currently senotsa supports algorithm module written in three languages including c python and r these three languages represent three ways how algorithm module works in sentosa c traders using c mostly have strong programming skills and higher requirement with trading system s performance and speed in sentosa trading system algorithm module is built into a static library and then used to generate the final executable binary all algorithms in sentosa trading system inherit from an abstract base class algoengine factory pattern is used to create algorithm objects algoengine algofac const string if boost iequals return if boost iequals return return nullptr in sentosa configuration file sentosa yml there is a strategy section to specify you strategy name and trading universe take the following as an example strategies sina athm sohu yy wb renn cyou qunr spy fxi it means there is a strategy called and the trading universe includes stocks etfs sina athm fxi i name the strategy for an illustration purpose so that you can see this is a strategy using technical analysis in real trading traders normally give their strategies totally irrelevant names technical analysis ta indicators are extremely popular with individual traders they normally use it in low frequency trading there are many rules of thumb for ta indicators which are only applicable in low frequency trading environment for high frequency trading you may need to do some adjustment take rsi relative strength index an extremely popular indicator developed by j welles wilder jr as an example rsi is defined as rsi rs where rs averagegain averageloss according to wilder rsi is considered overbought when above and oversold when below if using seconds bar data for stocks trading not so frequently rsi can become very high or low because there are many periods without price change there are two solutions the first one is to use more time periods so that average gain or average loss is not equal to another solution is to set rsi equal to if the price changes are too few in other words the momentum is not obvious when there is no price change information so we just give it a value of the following is a c implementation of the second idea if number of price changes is less than just set rsi to double getrsi double p sz vector double vd p p sz auto i std unique vd begin vd end m distance vd begin i if m return int ob n endindex double result endindex sz endindex p sz ob n result return result some ta indicators working well in low frequency trading do not work at all in high frequency trading one reason is the market data like taq is not enough in high frequency especially for assets with low liquidity another reason is that market noise is significant sometimes dominant in high frequency trading too much unpredicted factors will make the real price trend unclear in this case more research and backtesting are needed to find out what the real value of the trading asset is and after how long the noise will disappear there is a ta library called ta lib written in c and also available in other languages like python go sentosa includes a development version of ta lib version you can also download ta lib version from http ta lib org which is more stable but with less ta indicators pythontraders using python do not have very high requirement on the execution speed and system performance i developed a python package called pysentosa which uses nanomsg protocol to connect to market data module and websocket protocol to connect to oms a demo code is like the following from pysentosa import merlion from ticktype import m merlion target spy m target bita bounds target while true symbol ticktype value m if symbol target if ticktype and value bounds symbol oid m buy symbol while true m oid print ordstatus if filled bounds symbol break sleep elif ticktype and value bounds symbol oid m sell symbol bounds symbol code demonstrates a simple algorithm set a price range with lower bound equal to and upper bound equal to if spy s ask price is lower than try to buy shares if the buy order get filled decrease the lower bound by and wait to buy shares until the ask price hit below but if the bid price is greater than the upper bound value send a sell order of shares spy if get filled increase the upper bound by and wait to sell until the bid price hit beyond the new upper bound value this algorithm can be used to split big order for institutional traders not only is pysentosa a message interface of sentosa it includes a sentosa trading system runtime i use boost python to wrap sentosa trading system into a dynamic library and it will be run as a daemon when you create a merlion object in another words pysentosa is a complete full featured trading system rin contrast with pysentosa i also developed rsentosa with r language which is to demonstrate another way to use sentosa rsentosa is for traders using r language who normally have strong statistics background rsentosa use nanomsg protocol to communicate with both oms and market data module the demo code is as follows library rsentosa c spy bita while v symbol v tktype v value v cat symbol tktype value n if symbol spy if tktype as double value oid buy symbol while oid cat order status n if filled cancelled break sys sleep if filled the algorithm is almost the same as the python version except it does not sell spy no matter what bid price is order management systemoms order management systems is a software system to facilitate and manage the order execution typically through the fix protocol in sentosa oms module gets orders from algorithm module and send them to ib ib gets order from sentosa oms and executes it using its smart routing technology ib api supports two basic type of orders limit order and market order limit orderlimit order has a price limit which guarantees the execution price cannot be worse than it for every stock exchange maintains a limit order book including all the bid ask prices volumes and timestamp information please be noted the trade price can be favorable than limit order price for example if you send a limit order of selling google stock for dollar per share system will fill it with the bid price at the top of the book which will be higher than dollar market ordera market order itself has no price information when a market order is sent out to an exchange the order matching engine will find the currently available best price to execute it market order will normally be filled immediately by matching another limit order at the top of order book you cannot match two market orders because there is no price information in market orders oms design and messaging protocoloms accepts two type of protocols nanomsg and websocket thread will monitor and handle any incoming nanomsg message at port specified as in sentosa yml thread will monitor and handle any incoming websocket message at port specified as sentosa yml oms handles two different protocols but with the same logic i use c function overloading to handle the difference the interface definition is at cpp and implementation is at cpp for nanomsg and cpp for websocket respectively sentosa is a multithread application where there are four threads in oms module sentosa for performance consideration system will preallocate a static array of orders with length of for each instrument in another words one instrument can send at most orders with different order id order replacement is not counted in as the order id is the same this number should be enough for individual traders sentosa oms uses nanomsg as the communication protocol and receives nanomsg text as the instruction sentosa oms opened a socket at the following endpoint string endpoint tcp localhost cr you can customize the port by changing at sentosa yml the protocol specification is also customizable through sentosa yml take the default sentosa yml configuration as an example protocol closeall e closeone f cancelall g lmtorder l mktorder m orderid i where closeallto close all your current position with market order when a nanomsg text starting with e is received closeoneto close one instrument s position as soon as possible the nanomsg format is f symbol for instance f ibm means to close your current ibm holding position with a market order cancelallto cancel all your current outstanding orders of one instrument the nanomsg format is g symobl lmtorderto send a limit order the format is l symbol quantity price allowedmove oid where quantity is a signed integer positive sign means buy and negative means sell price is the limit price allowedmove is the price range in which the order is still considered valid in sentosa oms if the market price moves too far from the limit price the order will be cancelled by oms the logic can be expressed with the following pseudo code if abs marketprice targetlimitprice allowedmove oid else oid oid is the order idmktorderto send a market order the format is m symbol quantity oid orderidto check the status of an order by order id the message format is i oid for instance i means a request to oms to return the status of the order with id equal to oms will send one of the following order s status to client with the format of i oid orderstatus in case the order doesn t exist at all oms will send back if oms send i back it means the order with id equal to has a status of submitted order status are defined like the following enum orderstatus newborn presubmitted submitted inactive filled cancelled you can refer to ib document for the details of order status https www interactivebrokers com en software api apiguide c orderstatus future directionsentosa trading system can be extended in several ways from multithread to multiprocessfrom single machine to clusterfrom ib to other trading venues or direct market access dma if possiblemore languages supportmore modules support risk management module portfolio management part iii sentosa research introductionsearch research platform is a web based interactive computing platform based on jupyter with python and r support you can set it up in your local machine and do research with your data the following is a screenshot sentosa research platformin the following sections i will discuss financial data selection collection and management then i will showcase two research tasks using r and python respectively the first is garch family volatility comparative study with low frequency data and the second is true volatility calculation with high frequency data data selection collection and managementin the first place successful trading starts with good quality data with good quality data particularly quantitative data trader can do meaningful research for equity trading some commonly used data types include trade data quote data fundamental data macroeconomic data risk factor data news data social media data and option data daily ohlc trade data and some macroeconomic data are normally available for free others are mostly not free some of which are expensive because of the information edge traders can get from them for the paid data services you need to choose to pay for processed data or raw data or both processed data eg pe pb ratio are more convenient and ready to be used directly as for raw data eg tick and quote data you need to write program to clean them calculate indicator or risk factors with your own algorithm some may need heavily intense computation but good thing for raw data is its flexibility and potential to provide a trader with more information edge data can be stored in file system in plain text format many time series data are just some csv files which can be very conveniently used by many languages for big data series database like mssql mysql and mongodb can be used data are stored in tables or documents and indexes are created for faster query speed for higher performance time series data processing you can choose commercial database like kdb one tick or extremedb there are many commercial data vendors out there like thomson reuters bloomberg but most of them are prohibitive for individuals in this project using mysql as data storage and ib as data source i developed a historical data collection tool called histdata which i will describe as below historical data collection tool histdatain this project i use four tables to store four time series data table nametime series trade bar seconds trade bar seconds quote bar data bid seconds quote bar data ask the table structure is the same for each table for example the following is the structure of table fieldtypekeycommentsvarchar multicker symbolofloatopen pricehfloathighest price of the daylfloatlowest price of the daycfloatclose pricevint trading volumewfloatwap weighted average price bcmediumint bar count number of trades dtdatemuldatethe following are three rows in table first row means during dec to dec there are trades occurred for bita with wap equal to trading volume equal to open price equal to highest price equal to lowest price equal to and close price equal to the major challenge to collect data is to conform to the rule of historical data limitation https www interactivebrokers com en software api apiguide tables htmfor stocks historical data requests that use a bar size of secs or less can only go back six months ib also has limitation in request rate which requires no more than historical data requests in any minute period considering this limitation i think ib should have used traffic control algorithm like token bucket in the server side in client side to avoid causing pacing violations our data collector sleeps for minute after sending requests this is customizable in configuration file sentosa yml the following is what i used in my configuration file histdatareqnum histdatasleept milliseconds histdatabackmn how many months from now if histdatasleept is equal to histdatareqnum should be equal to which means sleep seconds per requests histdatabackmn means how many months from now backward you want to collect data in the above example if today is dec it means we want to collect data in period of jul to dec as follows i will showcase how to use sentosa research platform to do quantitative research on volatility case is about parametric models of volatility using low frequency data case is about nonparametric models using high frequency data with market microstructure noise case volatility forecasting comparative study r volatility is so important that it is widely used in trading pricing and risk management christian brownlees rob engle and bryan kelly published a paper called a practical guide to volatility forecasting through calm and storm which concludes that model rankings are insensitive to forecast horizon to verify the conclusion of this paper i plan to use quandl library to get s p index data from jan to mar and use r program to compare garch models garch ngarch tgarch aparch egarch in the models garch model fails to explain the asymmetry of the distribution of errors and the leverage effect egarch and tgarch are able to handle leverage effect where return has negative skewness ngarch and aparch are able to handle leverage effect for both negative and positive skewness the code is written in r language as follows rm list ls options digits library rugarch library timeseries library forecast library quandl quasi likelihood ql loss function function squaredr varforecast tmp squaredr varforecast return tmp log tmp function specs horizons rownum length specs colnum length horizons result matrix rownum colnum nrow rownum ncol colnum dimnames list horizons j for horizon in horizons i for in specs ugarchfit rtn spec out sample solver hybrid ugarchforecast n ahead horizon squaredr rtnsquare length rtnsquare horizon varforecast sigma horizon loss squaredr varforecast cat i loss sep result i j loss i i j j return result get data quandl yahoo type xts rtn na omit returns rtnsquare rtn arimafit auto arima as numeric rtn c arimafit arma models specs norm ugarchspec mean model list armaorder variance model list model fgarch submodel garch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel ngarch distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel tgarch distribution model ugarchspec mean model list armaorder variance model list model egarch submodel null distribution model ugarchspec mean model list armaorder variance model list model fgarch submodel aparch distribution model specs c c garch ngarch tarch egarch aparch verification horizons c result specs horizons n length horizons m length par mfrow c n bg white colors c red green purple blue black darkred for i in seq n paste forecast horizon horizons i dist sep plot result i type b xaxt n pch col colors i main xlab ylab quasi loss grid null null lty col axis at seq m labels the code above defines a quasi likelihood ql loss function proposed by the original paper by which we can compare model s predictability then it gets data from quandl defines model specifications fits models and predicts with each model and finally draws a graph with quasi likelihood ql loss value the out sample length is days the forecast horizons i have chosen are days i will compare the five models predictability in these forecast horizons assuming that the return distribution is normal run the code above and i find when forecast horizon is equal to or less than ngarch garch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result is at figure garch family models with normal distributionas we know stock price return distribution is more aligned with student t distribution than normal now assuming the return distribution is student t distribution in the code we need to change the model specification from norm to std std run the code above and i find when forecast horizon is equal to or less than garch ngarch aparch tarch egarchwhen forecast horizon is greater than no ranking pattern is observed the result can be seen from figure garch family models with student distributionthe result verifies the model ranking doesn t change as the forecast horizon changes as long as the horizon is not too large it can be explained by the characteristics of each model for example both tarch and egarch consider positive skew leverage effect so they have almost the same loss function value ngarch and aparch can explain both positive and negative skewness which is why it has a higher loss function value than tarch and egarch the result also verifies another empirical knowledge that compared with other garch family models garch model is good enough when we use student distribution as the model distribution garch model ranks number when using normal distribution garch ranks number this is another example that the simplest model is the most powerful model case volatility with high frequency data python theory and concept assume stock price follows geometric brownian motion st exp wt t then stock return ri log si log si is a normal distribution in one unit of time ti the sum of squared return ri aka quadratic variation of ri is i i log sti sti i wti wti ti ti so the definition of volatility in mathematical form is i log sti sti this volatility is called true volatility is called true variance i log sti sti market microstructure effectshigh frequency data have some unique characteristics that do not appear in lower frequencies there are several well known phenomenon like asynchronous trading bid ask bounce and minimum tick rules which are called market microstructure effects in finance literatures figure is generated from bita compounded return time series with different sampling intervals minute hour and day in the distribution subplots the red dashed line is the corresponding normal distribution when interval length is day the distribution is a right skewed leptokurtic bell curve however as the sampling frequency increases the skewness decreases and kurtosis increases when interval length is minute skewness becomes negative and kurtosis reaches as high as market microstructure effects on log returnthis means the data statistic property has been changed when the sampling frequency increases in high frequency data the observed price is not the stock s intrinsic price any more but a trade price heavily distorted by market microstructure effects suppose the logarithm of a stock intrinsic true price is a stochastic process pt and observed trade price is qt i use pt to represent a stochastic process which is unknown and equal to the logarithm of a stock intrinsic or true price and qt is another stochastic process which equals to the logarithm of a stock s trade price the model is qt pt t or qt log st tpt log st where t is an i i d noise process with e t t e c noise variance c is a constant in this model it is not necessarily normal but should be symmetric and weak stationary also t is independent with pt and qt realized volatility and volatility proxiesalthough we have a math formula for true volatility we can never get its precise value first it is a continuous calculus form equation but in the real world the price is always discrete second market microstructure effects as described in previous section also distort the price making trade price not exactly the same as stock s intrinsic price as defined in our model in order to make the return data close to normal distribution which is a basic assumption in many financial models one has to sample the trade price at sufficiently wide interval to avoid market microstructure effects and in turn this will make the price more discrete so we have to introduce another concept called realized volatility it is essentially a discrete version of true volatility defined at equation if we split the time unit t equally into n smaller time intervals t with equal length we have the sampling frequency n n t t and realized volatility is defined as t i qti qti and the realized variance is accordingly defined as i qti qti please be noted here q is observed price not true price s realized volatility aka integrated volatility is a bias estimator of true volatility due to market microstructure effects i will prove this theoretically and empirically later correspondingly the square of realized volatility is called realized variance or integrated variance or sometimes realized quadratic variation please be noted in some literatures realized volatility and realized variance sometimes are used interchangeably in addition there are two other volatilities often seen in literatures implied volatility is just a numeric calculated from the option price according to black scholes formula assuming all the assumptions of black scholes model are correct historical volatility normally means the past daily volatility calculated with historical data according to parametric conditional volatility models like garch ewma or stochastic volatility models because true volatility is not known one can use volatility proxies when specifying and evaluating volatility models we can consider proxy as a mapping of original variable in another space through a proxy function in statistics proxy is used for a variable not of prime interest itself but is closely connected to an object of interest one uses proxy to replace latent variables of interest so the absolute correlation of proxy variable and original variable should be close to please be noted that one can use estimator either biased or unbiased as a proxy but it is probably wrong to use a proxy as an estimator market microstructure effects and volatility proxiesrealized variance is often used as a volatility proxy when high frequency data are available but surprisingly due to market microstructure effects we may get worse result when we have higher frequency data for the noise process we have e t e s because s and t are independent and then e t s e e t e s for realized variance we have i qti qti i pti pti ti ti i rti ti ti the expectation is e e i rti ti ti e i rti ti ti ti ti e the variance is var op this proves realized variance is a biased estimator of true volatility the higher the sampling frequency is the bigger n is and the bigger the bias is when n goes to infinity the bias and realized variance go to infinity too zhang proposed that when n is large enough will become negligible we can get the value of c the variance of noise process with this formula c e once we get the value of c we can use the same equation to get e but how to decide if n is large enough i am proposing another method resample the raw data with two steps and and get two expectation of realized variance e and e we have e e e e so we get c by c e e other volatility proxiesprice range is a good volatility proxy which is free from the market microstructure effects one definition is as simple as pr qh ql where qh is the highest trade price in one time unit ql is the lowest price accordingly the expectation of price range is e pr e qh ql e ph pl h l e ph pl we can see it is related to spread of true price in one time unit but has nothing to do with t another method to construct price range using high frequency data is to sum all subinterval price spreads in one time unit to avoid confusion if necessary i will use price range h l for the first definition and price range sum of h l for the second one by default price range means the first definition in addition people sometimes also use absolute return as volatility proxy it is very similar to price range but because the log return only consider the last close price and current close prices it will miss information between the two time points so it has a downward bias realized variance and other volatility proxiesrealized variance is a biased estimator also a proxy of real variance first let s compare it with another well known volatility proxy price range the raw data is seconds ohlc bar data of bita from ib i choose minutes as the time unit so according to equation with sampling interval number n equal to we can get the value of realized variance it is noteworthy that for price range i use the highest price in minutes minus the lowest price not sum of high minus low in seconds ohlc bars i randomly choose one day and compare these two variance proxies the result is figure realized variance vs price range h l in one day the upper graph is the absolute value comparison because the value of realized variance is so small that it becomes a straight line closely above x axis after multiplying a scale up factor to every number in realized variance series i get the lower graph it looks much better than the upper one it is easy to see the two time series have the same trend there is only very minor difference between them figure verifies that price range is a good proxy for stock variance and volatility the proxy function in this case is just a multiplication to a constant now let s add two more proxies absolute return and price range sum of h l as described in previous section absolute return is calculated as log return of the time unit price range sum of h l is calculated by adding all high low difference in seconds ohlc bars in one time unit in my program and graphs i use rvar for realized variance prange for price range h l srange for price range sum of h l and absr for absolute return then i choose time units from minutes to day still using seconds ohlc bar data of bita i calculate volatility proxy for every time unit above after getting the results i check the statistics characteristics to verify the model from and we can get the variation coefficient k k var e op e suppose n is large enough if the time unit increases by m times m according to volatility time square root rule we have k m me this means if the sampling interval is fixed and n is large enough variation coefficient k of realized variance will decrease exponentially o as length of time unit increases to verify this conclusion i check the relation of variation coefficient and time units and get figure market microstructure effects on volatility proxies we can see market microstructure effects has a big impact on realized variance when length of time unit decreases the variation coefficient increases dramatically robin and marcel proved that smaller variance corresponds to better volatility proxy we can see the realized variance becomes stable and close to the other proxies when the time unit increases to hours for the other three proxies there is no obvious change of variation coefficient which means they do not suffer from market microstructure effects also it is well known that measurements that are log normally distributed exhibit stationary variation coefficient which is exp figure also implies true variance is log normally distributed a good proxy should have a close correlation with the original and other good proxies too figure displays the correlation coefficient changes with the time units we can see the correlation of realized variance and price range increases dramatically as length of time unit increases this means realized variance becomes a better proxy when the unit time is large enough say hours bias and consistency of volatility daily realized variance and noise processin previous section we fix the length of time interval t increase the time unit t and find that market microstructure effects has an exponential impact on realized variance in this section i am going to fix the time unit t as day and change the length of time interval t i will show how market microstructure noise process affects daily realized volatility when changing sampling time interval and investigate two ways to get the variance of noise process still using bita seconds ohlc bar data and equation but choosing three different time intervals seconds minutes and hours i get three daily realized variance time series and display them in figure daily realized variance at different sampling intervalsin figure means sampling interval is seconds means minutes and means hours we can see the trend is almost the same but red dots are distributed closer to x axis blue dots are the farthest and green dots are in between this means when sampling interval increases or when sampling frequency n decrease expectation of daily realized variance decreases accordingly this is an expected result according to equation now let s try more different sampling intervals i choose intervals as follows intervals number of seconds ohlc barcorrespondingly the time intervals are seconds minutes minutes minutes minutes minutes and minutes i get figure expectation of daily realized variance at different sampling intervalsthe x axis represents the sampling intervals and y axis represents expectation of daily realized variance which is asymptotically equal to sample mean we can see as sampling interval increases which corresponds to a smaller n the expectation of daily realized variance decreases this is in line with equation when the interval is seconds n is equal to because the trading hour is hours and a half this is the highest frequency data i can get assume n is large enough to ignore e in and to get population expectation e using the method proposed by zhang we can get that the noise process variance c equals to alternatively i tried to use equation too assuming the first two intervals and are large enough for population expectation e using equation i get the noise process variance c equal to the reason why the two results are different is seconds time interval is too long in another words the data frequency n is not high enough to ignore e according to the formula c e e when true variance is not negligible if one uses one will overestimate the denominator and then overestimate the noise process variance c fortunately equation doesn t require n is large enough to ignore e assuming equation is correct applied here c equals to when n in turn we can get expectation of true variance e e both equations and require higher frequency data but the latter only affected by accuracy of expectation calculation with the same frequency data equation is better because it doesn t require n is large enough to ignore e three schemes for realized variance calculationin previous section although we always use equation to calculate daily realized variance we have actually used two schemes scheme calculates squared return for every adjacent pair of prices sequentially in one unit of time t and then sum all squared returns figure illustrates how the calculation goes on i call it classical scheme as it is exactly from equation in previous section i verified classical scheme is most seriously affected by market microstructure effects because high frequency data are contaminated by the noise process when sampling frequency is high it demonstrates a strong upward bias making the result totally useless in realized variance time series calculated from this scheme you can see many spikes which corresponds to high variation coefficient classical scheme to calculate realized variancescheme splits one time unit into multiple grids grid is a new sample interval in between t and t scheme uses only one point of data in one grid ignoring all other data so i call it sparse sampling scheme in my program to generate figure and figure i use the first price to represent price of the new sampling time interval and calculate and figure illustrates how the calculation goes on sparse sampling scheme to calculate realized varianceaccording to theoretical and empirical analysis in previous section we see that sparse sampling scheme has a better performance than classical scheme this is very surprising as it uses much less data in figure if one cell represents a seconds ohlc bar we have cells for one day if the new sampling time interval is minute according to sparse sampling we need to throw away price data but when we use the remaining price data to calculate we get a even better result this sounds counterintuitive but can be perfectly explained by model please be noted there are two intervals in sparse sampling the original interval is seconds and the new interval after sparse sampling becomes minutes to avoid confusion i will use word grid for the latter in the future which is how zhang names it in the original paper can we take advantage of all data and throw away only the noise part in trade price here scheme comes into play it is a natural expansion of scheme it uses all data but also robust to market microstructure effects as displayed in figure we apply the same calculation of return like sparse sampling for not only the first cell in that grid but all the other data in figure there are four cells in one grid so we will get four results the final result will be the average of them this method is proposed by lan zhang i call it averaging scheme because it is improved by averaging based on sparse sampling scheme averaging scheme to calculate realized variancein theory averaging scheme should be better than the other two i am going to verify this as below averaging scheme vs classical schemestill using bita seconds ohlc data i get a comparison of classical scheme and averaging scheme in figure classical scheme vs averaging schemethe purple dots are realized variance result from classical scheme and the green ones from averaging scheme with grid length equal to hour seconds we can see the green dots are distributed at the bottom closer to x axis which corresponds to the overestimation issue of classical scheme this proved averaging scheme is better than classical scheme averaging scheme vs sparse sampling schemenow let s compare sparse sampling scheme and averaging scheme i choose grid lengths as follows using two schemes to calculate daily realized variance and then the expectation e under each grid the output is intervalaveraging schemesparse sampling it as figure below sparse sampling scheme vs averaging schemewe can see averaging scheme has a lower e than sparse sampling scheme this means the former suffers less from market microstructure noise so it is better please be noted if grid length becomes the same as sampling time interval sparse sampling scheme and averaging scheme are degraded to classical scheme this is why when grid length equals to seconds the purple dot and green dot becomes the same averaging scheme vs itselfwe have seen averaging scheme is the best of the three schemes we also see the grid length affects the results of averaging scheme let me increase grid from seconds to minutes and draw the realized variance time series at figure averaging scheme and different grid lengthwe can see the best result is the one with grid length equal to minutes we can display e with grid length in figure expectation of realized variance with averaging scheme and different grid length we can see the expectation curve is a smooth convex hull it decreases exponentially as grid length increases but after minutes e doesn t decrease any more this is because if grid length is too long we cannot use all the data any more averaging scheme becomes more like sparse sampling scheme for instance when grid length is the same as time unit t which is day in our case averaging scheme is degraded to sparse sampling scheme to verify this i choose grid lengths and draw e in figure averaging scheme and different grid lengthgreen curve is sparse sampling scheme and blue curve is averaging scheme x axis is grid length and y axis is e we can see for averaging scheme after e keep increasing in very slow speed also because averaging scheme is actually an average of many equally reasonable results it is smoother than sparse sampling scheme after sparse sampling scheme curve jumps up and down around averaging scheme curve this means there is an optimal value for grid length between sampling time interval t and time unit t in this case it is around minutes when grid length equals to t averaging scheme becomes classical scheme when it equals to t averaging scheme becomes sparse sampling scheme true variance and volatilityin previous sections i got the variance c of noise process t i also found that averaging scheme is the best way to calculate realized variance with grid length equal to minutes in this case i have reached my goal i am ready to calculate true variance and true volatility now see figure for true volatility series i created using the information above true volatilityi can also get the statistics of true variance time series take logarithm of true variance and we can get the distribution at figure logarithmic true variance distributionthe dashed blue line is the normal distribution curve fitted with the same mean and standard deviation as above we can see the distribution is close to normal we know variance has properties like clustering and mean reversion and now we know logarithm of variance is gaussian distribution or variance is lognormal distribution this also supports the conclusion i get from figure that stationary variation coefficient of volatility proxies implies they are log normally distributed true volatility is the square root of true variance i checked the distribution and it is also lognormal previously we use price range as a proxy of true variance now we can check the distribution of price range and see if it has the same distribution as true variance figure is the daily price range series and distribution i get from our bita dataset logarithmic price range distributionthe red dashed line is normal distribution curve fitted with corresponding mean and standard deviation the distribution is very similar with figure this is in line with our knowledge that price range is a good proxy for true variance data selection and conclusion generalityto take a new nonparametric approach to calculate volatility i need high frequency data the data i use in this case study is bita seconds ohlc bar data from to i got the data with the histdata tool which i have described in section historical data collection tool histdata there are bars in the dataset stored as a csv format file named csv you can download it from http www com post i also want to emphasize that the bita data are picked from the database randomly it has no special importance itself the conclusion drawn from previous sections should also apply to other stocks it is noteworthy that for two adjacent ohlc bars close price of the first bar is not necessarily equal to open price of the second bar when we calculate return we have to use two bars to calculate close to close return but when we calculate price range we can use high price minus low price in the same bar future directionconsider relation between noise process and trading frequency in the noise process modelmore programming languages supportcluster for faster computing spark lightning fast cluster computing for monte carlo simulation and big matrix calculationintegration with sentosa trading system and web part iv sentosa web platforminitially sentosa web platform is a django blog website called qblog that i developed to write trading diary which features markdown and mathematical formula support later i added a sentosaapp module to monitor and debug sentosa trading system finally i extended it to be able to interact with sentosa trading system completely it uses javascript websocket to communicate with sentosa trading system and displays internal status at webpage using jquery it can also be used to send orders to sentosa trading system although this is a very important part of sentosa it is not directly related to any finance knowledge so i just introduce it very briefly in one page for more details please check sentosa website the following is the screenshot of sentosa web platform sentosa web platform in backtesting mode with real historical dataas for future development this web platform can be extended to do online trading
hello admin this email contains highly confidential information regarding office site closure the following offices are closing down arizona us new mexico us tampa us please keep this information safe at all times
